{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8AbtMQfMUkt"
      },
      "source": [
        "# Evolutionary Camouflage Versus a Learning Predator\n",
        "EvoCamoVsLearningPredator.ipynb\n",
        "\n",
        "Just a copy of Evo_Camo_vs_Static_FCD.ipynb as of 20220403\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr9fUxZxJBRl",
        "outputId": "aedbed59-2c45-49a2-a936-aca1abb74478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "# # Shared \"communication\" directory on Drive.\n",
        "# shared_directory = '/content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/'\n",
        "\n",
        "# # Pathname of pre-trained Keras/TensorFlow model\n",
        "# saved_model_directory = '/content/drive/My Drive/PredatorEye/saved_models/'\n",
        "\n",
        "# PredatorEye directory on Drive.\n",
        "pe_directory = '/content/drive/My Drive/PredatorEye/'\n",
        "\n",
        "# Shared \"communication\" (\"comms\") directory on Drive.\n",
        "# shared_directory = '/content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/'\n",
        "shared_directory = pe_directory + 'evo_camo_vs_static_fcd/'\n",
        "\n",
        "# Directory for pre-trained Keras/TensorFlow models on Drive.\n",
        "# saved_model_directory = '/content/drive/My Drive/PredatorEye/saved_models/'\n",
        "saved_model_directory = pe_directory + 'saved_models/'\n",
        "\n",
        "# Pathname of pre-trained Keras/TensorFlow model\n",
        "# trained_model = saved_model_directory + '20220202_1211_Find_3_Disks_complex'\n",
        "# trained_model = saved_model_directory + '20220222_1747_F3D_augmented_rc4'\n",
        "# trained_model = saved_model_directory + '20220227_0746_F3D2_a'\n",
        "# trained_model = saved_model_directory + '20220304_1135_FCD5_a'\n",
        "trained_model = saved_model_directory + '20220321_1711_FCD6_rc4'\n",
        "model = []\n",
        "\n",
        "# Directory on Drive for storing fine-tuning dataset.\n",
        "fine_tuning_directory = shared_directory + 'fine_tuning/'\n",
        "\n",
        "my_prefix = \"find_\"\n",
        "other_prefix = \"camo_\"\n",
        "\n",
        "my_suffix =  \".txt\"\n",
        "# other_suffix = \".jpeg\"\n",
        "other_suffix = \".png\"\n",
        "\n",
        "fcd_image_size = 1024\n",
        "fcd_disk_size = 201\n",
        "\n",
        "import time\n",
        "import PIL\n",
        "################################################################################\n",
        "# TODO 20220420\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Came upon Python 3's 'pathlib' https://docs.python.org/3/library/pathlib.html\n",
        "# while fixing a bug. I think the API below is obsolete and should be replaced.\n",
        "from os import listdir\n",
        "# from os import remove\n",
        "from os.path import join\n",
        "from os.path import split\n",
        "# from os.path import isfile\n",
        "################################################################################\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')\n",
        "\n",
        "# Import DiskFind utilities for PredatorEye.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
        "import DiskFind as df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCxVUKpMTEcN"
      },
      "source": [
        "# Ad hoc “predator server”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZF4XLFSBTKOM"
      },
      "outputs": [],
      "source": [
        "# Top level: wait for camo_xxx.jpeg files to appear, respond with find_xxx.txt\n",
        "def start_run(step = 0):\n",
        "    if step == 0:\n",
        "        print('Start run in', shared_directory )\n",
        "        list_unexpected_files(shared_directory)\n",
        "    else:\n",
        "        print('Continue run at step', step, ' in', shared_directory)\n",
        "    while True:\n",
        "        performStep(step, shared_directory)\n",
        "        step += 1\n",
        "\n",
        "# Continue from from the last camo_xxx.jpeg file.\n",
        "def restart_run():\n",
        "    start_run(newest_file_from_other(shared_directory))\n",
        "\n",
        "# Single step: wait for camo file, write response, delete previous response.\n",
        "def performStep(step, directory):\n",
        "    waitForReply(step, shared_directory)\n",
        "    print('Write file', step)\n",
        "    writeResponseFile(step, shared_directory)\n",
        "    deleteMyFile(step - 1, shared_directory)\n",
        "\n",
        "# Read image file for step, apply pre-trained model, write response file.\n",
        "def writeResponseFile(step, directory):\n",
        "    # Read image file and check for expected format.\n",
        "    image_pathname = makeOtherPathname(step, directory)\n",
        "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "    assert df.check_pixel_tensor(pixel_tensor), ('wrong file format: ' +\n",
        "                                                 image_pathname)\n",
        "    # Run pre-trained model on new image.\n",
        "    prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "    # Generate response file.\n",
        "    response_string = str(prediction[0]) + \" \" + str(prediction[1])\n",
        "    print('response_string ' + \"'\" + response_string + \"'\")\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(makeMyPathname(step, directory), 'w') as file:\n",
        "        file.write(response_string)\n",
        "    print(\"wrote response file\", makeMyPathname(step, directory))\n",
        "    # Predator learns from recent experience.\n",
        "    fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220428\n",
        "\n",
        "# # Delete the given file, usually after having written the next one.\n",
        "# def deleteMyFile(step, directory):\n",
        "#     path = makeMyPathname(step, directory)\n",
        "#     if isfile(path):\n",
        "#         remove(path)\n",
        "\n",
        "# Delete the given file, usually after having written the next one.\n",
        "def deleteMyFile(step, directory):\n",
        "    # Why doesn't pathlib provide a Path.remove() method like os?\n",
        "    # TODO oh, missing_ok was added at pathlib version 3.8.\n",
        "    # Path(makeMyPathname(step, directory)).unlink(missing_ok=True)\n",
        "    p = Path(makeMyPathname(step, directory))\n",
        "    if p.exists():\n",
        "        p.unlink()\n",
        "\n",
        "# def clean_up_communication_directory():\n",
        "#     comms_path = Path(shared_directory)\n",
        "#     for thing in comms_path.iterdir():\n",
        "#         thing.unlink()\n",
        "\n",
        "def clean_up_communication_directory():\n",
        "    for path in Path(shared_directory).iterdir():\n",
        "        path.unlink()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# From pathname for file of given step number from the \"other\" agent.\n",
        "def makeOtherPathname(step, directory):\n",
        "    return directory + other_prefix + str(step) + other_suffix\n",
        "\n",
        "# Form pathname for file of given step number from \"this\" agent.\n",
        "def makeMyPathname(step, directory):\n",
        "    return directory + my_prefix + str(step) + my_suffix\n",
        "\n",
        "def makePreyPathname(step, directory):\n",
        "    return directory + 'prey_' + str(step) + '.txt'\n",
        "\n",
        "# Wait until other agent's file for given step appears.\n",
        "def waitForReply(step, directory):\n",
        "    print('start waiting for  ', makeOtherPathname(step, directory))\n",
        "    start_time = time.time()\n",
        "    while not isFilePresent(makeOtherPathname(step, directory)):\n",
        "        time.sleep(2)  # wait 2 sec\n",
        "    print('done waiting for   ', makeOtherPathname(step, directory))\n",
        "    print('Elapsed time:', int(time.time() - start_time), 'seconds.')\n",
        "\n",
        "# Like fs::exists()\n",
        "def isFilePresent(file):\n",
        "    result = False\n",
        "    (directory, filename) = split(file)\n",
        "    for i in listdir(directory):\n",
        "        if i == filename:\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "# Actually I guess the counterparty may have already written its first...\n",
        "def list_unexpected_files(directory):\n",
        "    directory_contents = listdir(directory)\n",
        "    if directory_contents:\n",
        "        print('Unexpected files:', directory_contents)\n",
        "\n",
        "# Returns the step number of the newest file from \"other\" in given directory.\n",
        "# (So if \"camo_573.jpeg\" is the only \"other\" file there, returns int 573)\n",
        "def newest_file_from_other(directory):\n",
        "    steps = [0]  # Default to zero in case dir is empty.\n",
        "    for filename in listdir(directory):\n",
        "        if other_prefix == filename[0:len(other_prefix)]:\n",
        "            steps.append(int(filename.split(\".\")[0].split(\"_\")[1]))\n",
        "    return max(steps)\n",
        "\n",
        "# Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
        "# https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
        "# of this parameter.)\n",
        "# max_training_set_size = 200\n",
        "# max_training_set_size = 100\n",
        "max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
        "\n",
        "fine_tune_images = []\n",
        "fine_tune_labels = []\n",
        "\n",
        "# Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
        "# training set. Assume they were \"near misses\" and so training label is actual\n",
        "# (ground truth) center of disk nearest prediction. Keep a max number of old\n",
        "# steps to allow gradually forgetting the earliest part of the run.\n",
        "def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
        "    # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
        "    label_for_fine_tuning = center_of_nearest_prey(prediction, step, directory)\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220428 \n",
        "    # This is repetitive, it was just called inside center_of_nearest_prey().\n",
        "    # If this experimental code is kept, rethink how to structure this\n",
        "    xy3 = read_3_centers_from_file(step, directory)\n",
        "    print('xy3 =', xy3)\n",
        "    print('label_for_fine_tuning =', label_for_fine_tuning)\n",
        "\n",
        "\n",
        "    # 20220428 was trying to get to sorting xy3 by distance to prediction\n",
        "    # new_prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "\n",
        "    ############################################################################\n",
        "\n",
        "    # Accumulate the most recent \"max_training_set_size\" training samples.\n",
        "    global fine_tune_images\n",
        "    global fine_tune_labels\n",
        "    fine_tune_images.append(pixel_tensor)\n",
        "    fine_tune_labels.append(label_for_fine_tuning)\n",
        "\n",
        "    # If training set has become too large, slice off first element of each.\n",
        "    if len(fine_tune_images) > max_training_set_size:\n",
        "        fine_tune_images = fine_tune_images[1:]\n",
        "        fine_tune_labels = fine_tune_labels[1:]\n",
        "        # print('Trim fine-tune training set to max_training_set_size.')\n",
        "\n",
        "    # Convert training data list to np arrays\n",
        "    images_array = np.array(fine_tune_images)\n",
        "    labels_array = np.array(fine_tune_labels)\n",
        "    print('images_array.shape =', images_array.shape)\n",
        "    print('labels_array.shape =', labels_array.shape)\n",
        "\n",
        "    # Do fine-tuning training step using data accumulated during run.\n",
        "    history = model.fit(x=images_array, y=labels_array)\n",
        "    # Keep log of in_disk metric:\n",
        "    write_in_disk_log(step, history)\n",
        "\n",
        "    # TEMP keep?\n",
        "    # visualize change from train step:\n",
        "    new_prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "    before = df.dist2d(prediction, label_for_fine_tuning)\n",
        "    after = df.dist2d(new_prediction, label_for_fine_tuning)\n",
        "    d = after - before\n",
        "    note = 'INCREASED:'\n",
        "    if before > after :\n",
        "        note = 'DECREASED:'\n",
        "    print(note, \"{:.4f}\".format(d),\n",
        "          '(before:', \"{:.4f}\".format(before),\n",
        "          'after:', \"{:.4f}\".format(after), ')')\n",
        "\n",
        "# 20220408 \n",
        "# Given the xy prediction from the current predator model, read the ground truth\n",
        "# prey locations in the \"prey_n.txt\" file, return the one nearest to the current\n",
        "# prediction. Effectively, assume the predator was \"aiming for\" that one but\n",
        "# missed by a bit.\n",
        "def center_of_nearest_prey(predict, step, directory):\n",
        "    prey_centers = read_3_centers_from_file(step, directory)\n",
        "    # SURELY there is a more \"pythonic\" way to do this (select min distance)\n",
        "    min_distance = float('inf')\n",
        "    nearest_center = []\n",
        "    for prey_center in prey_centers:\n",
        "        # print('prey_center =', prey_center)\n",
        "        distance = df.dist2d(prey_center, predict)\n",
        "        # print('distance =', distance)\n",
        "        if min_distance > distance:\n",
        "            min_distance = distance\n",
        "            nearest_center = prey_center\n",
        "        # print('min_distance =', min_distance)\n",
        "        # print('nearest_center =', nearest_center)\n",
        "    return nearest_center\n",
        "\n",
        "# Read ground truth prey center location data provided in \"prey_n.txt\" file.\n",
        "def read_3_centers_from_file(step, directory):\n",
        "    # Read contents of file as string.\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(makePreyPathname(step, directory), 'r') as file:\n",
        "        prey_centers_string = file.read()\n",
        "    # Split string at whitespace, map to 6 floats, reshape into 3 xy pairs.\n",
        "    return np.reshape(list(map(float, prey_centers_string.split())), (3, 2))\n",
        "\n",
        "# Keep log of in_disk metric.\n",
        "def write_in_disk_log(step, history):\n",
        "    if step % 10 == 0:\n",
        "        in_disk = history.history[\"in_disk\"][0]\n",
        "        pathname = shared_directory + 'in_disk_log.csv'\n",
        "        verify_comms_directory_reachable()\n",
        "        with open(pathname, 'a') as file:\n",
        "            if step == 0:\n",
        "                file.write('step,in_disk\\n')\n",
        "            file.write(str(step) + ',' + \"{:.4f}\".format(in_disk) + '\\n')\n",
        "\n",
        "# Just wait in retry loop if shared \"comms\" directory become unreachable.\n",
        "# Probably will return shortly, better to wait than signal a file error.\n",
        "# (This is called from places with a local \"directory\" but it uses global value.)\n",
        "def verify_comms_directory_reachable():\n",
        "    seconds = 0\n",
        "    # shared_directory_pathname = Path(shared_directory)\n",
        "    # while not shared_directory_pathname.is_dir():\n",
        "    while not Path(shared_directory).is_dir():\n",
        "        print(\"Shared “comms” directory,\", shared_directory, \n",
        "              \"has been inaccessible for\", seconds, \"seconds.\")\n",
        "        time.sleep(1)  # wait 1 sec\n",
        "        seconds += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDtbk88sVGxk"
      },
      "source": [
        "# Read pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLVIRi_vU9gN",
        "outputId": "a353093a-d63f-4dd5-a3b5-722decec4ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pre-trained model from: /content/drive/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n"
          ]
        }
      ],
      "source": [
        "# Read pre-trained TensorFlow \"predator vision\" model.\n",
        "\n",
        "print('Reading pre-trained model from:', trained_model)\n",
        "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
        "#\n",
        "# dependencies = {\n",
        "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
        "#     'attention': attention(return_sequences=True)\n",
        "# }\n",
        "#\n",
        "# dependencies = {\n",
        "#     'valid_accuracy': ValidAccuracy\n",
        "# }\n",
        "\n",
        "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
        "def fcd_disk_radius():\n",
        "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
        "# distance between corresponding points in the input tensors.\n",
        "def corresponding_distances(y_true, y_pred):\n",
        "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
        "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
        "    dx = true_pos_x - pred_pos_x\n",
        "    dy = true_pos_y - pred_pos_y\n",
        "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
        "    return distances\n",
        "\n",
        "# 20211231 copied from Find_Concpocuous_Disk\n",
        "def in_disk(y_true, y_pred):\n",
        "    distances = corresponding_distances(y_true, y_pred)\n",
        "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "    # From https://stackoverflow.com/a/42450565/1991373\n",
        "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
        "    # insides = tf.less(distances, relative_disk_radius)\n",
        "    insides = tf.less(distances, fcd_disk_radius())\n",
        "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
        "    return map_to_zero_or_one\n",
        "\n",
        "dependencies = { 'in_disk': in_disk }\n",
        "\n",
        "model = keras.models.load_model(trained_model, custom_objects=dependencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itBD_Ve0lEYB"
      },
      "source": [
        "# Run test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "iZQLL52Sk-X9",
        "outputId": "9a8b5f43-a48f-474c-ee11-1abb6ef1fd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start run in /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "start waiting for   /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_0.png\n",
            "done waiting for    /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_0.png\n",
            "Elapsed time: 28 seconds.\n",
            "Write file 0\n",
            "response_string '0.7893729 0.54864895'\n",
            "wrote response file /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/find_0.txt\n",
            "xy3 = [[0.647294 0.253461]\n",
            " [0.773441 0.52646 ]\n",
            " [0.48889  0.642212]]\n",
            "label_for_fine_tuning = [0.773441 0.52646 ]\n",
            "images_array.shape = (1, 128, 128, 3)\n",
            "labels_array.shape = (1, 2)\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 2.4755e-04 - accuracy: 1.0000 - in_disk: 1.0000\n",
            "DECREASED: -0.0112 (before: 0.0273 after: 0.0161 )\n",
            "start waiting for   /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_1.png\n",
            "done waiting for    /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_1.png\n",
            "Elapsed time: 40 seconds.\n",
            "Write file 1\n",
            "response_string '0.39830464 0.41026562'\n",
            "wrote response file /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/find_1.txt\n",
            "xy3 = [[0.374532 0.758717]\n",
            " [0.6717   0.784025]\n",
            " [0.405528 0.417982]]\n",
            "label_for_fine_tuning = [0.405528 0.417982]\n",
            "images_array.shape = (2, 128, 128, 3)\n",
            "labels_array.shape = (2, 2)\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.5000 - in_disk: 0.5000\n",
            "INCREASED: 0.0133 (before: 0.0106 after: 0.0238 )\n",
            "start waiting for   /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_2.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cce6584bb524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mclean_up_communication_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mrestart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1bf6fba7a32d>\u001b[0m in \u001b[0;36mrestart_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Continue from from the last camo_xxx.jpeg file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrestart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewest_file_from_other\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Single step: wait for camo file, write response, delete previous response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1bf6fba7a32d>\u001b[0m in \u001b[0;36mstart_run\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Continue run at step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mperformStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1bf6fba7a32d>\u001b[0m in \u001b[0;36mperformStep\u001b[0;34m(step, directory)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Single step: wait for camo file, write response, delete previous response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperformStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mwaitForReply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Write file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mwriteResponseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1bf6fba7a32d>\u001b[0m in \u001b[0;36mwaitForReply\u001b[0;34m(step, directory)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misFilePresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmakeOtherPathname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait 2 sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done waiting for   '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmakeOtherPathname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Elapsed time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Normally start from step 0, or if an \"other\" file exists\n",
        "# (eg 'camo_123.jpeg') then restart from that point.\n",
        "################################################################################\n",
        "# TODO 20220427\n",
        "# TODO WIP on saving tine-tuning dataset to Drive\n",
        "\n",
        "# def read_image_file_as_pixel_tensor(image_pathname):\n",
        "#     # Read image file.\n",
        "#     image = PIL.Image.open(image_pathname)\n",
        "#     # Convert to numpy pixel tensor as 32 bit floats.\n",
        "#     pixel_tensor = np.asarray(image, dtype=np.float32)\n",
        "#     # Scale input image data to range [0, 1]\n",
        "#     pixel_tensor = np.interp(pixel_tensor, [0, 255], [0, 1]).astype(np.float32)\n",
        "#     return pixel_tensor\n",
        "\n",
        "\n",
        "# # Read image file at given pathname, pre-process for use in training model.\n",
        "# # def make_complex_example(image_pathname):\n",
        "# def f3d_make_training_example(image_pathname):\n",
        "#     # Read image file.\n",
        "#     pixels = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "#     # Check for expected format.\n",
        "#     if not df.check_pixel_tensor(pixels):\n",
        "#         msg = 'wrong image format, shape='+str(pixels.shape)+': '+image_pathname\n",
        "#         assert False, msg    \n",
        "#     # Parse disk center position from file name.\n",
        "#     filename = os.path.basename(image_pathname)\n",
        "#     center_position = df.fcd_normalized_xy(filename, pixels)\n",
        "#     return (pixels, center_position)\n",
        "\n",
        "\n",
        "# def test_jig():\n",
        "#     df.reset_random_seeds()\n",
        "#     # pn = '/content/drive/My Drive/temp/crqtVaibvq_26_105.png'\n",
        "#     pn = '/content/drive/My Drive/temp/jQREPLQyuL_33_39.png'\n",
        "#     ti, tl = f3d_make_training_example(pn)\n",
        "#     df.draw_image(ti, tl)\n",
        "#     for i in range(10):\n",
        "#         mi, ml = f3d_modify_training_example(ti, tl)\n",
        "        \n",
        "#         print('mi.shape =', mi.shape)\n",
        "#         print('ml.shape =', ml.shape)\n",
        "\n",
        "#         df.draw_image(mi, ml)\n",
        "# test_jig()\n",
        "\n",
        "# def ensure_fine_tuning_directory_exists():\n",
        "#     # TODO ERROR, needs to construct directory #################################\n",
        "#     if (Path(fine_tuning_directory).is_dir()):\n",
        "#         print('Already exists:', fine_tuning_directory)\n",
        "#     else:\n",
        "#         print('About to mkdir for:', fine_tuning_directory)\n",
        "#     Path(fine_tuning_directory).mkdir(exist_ok=True)\n",
        "\n",
        "def test():\n",
        "    pn = '/content/drive/My Drive/temp/jQREPLQyuL_33_39.png'\n",
        "    pixels = df.read_image_file_as_pixel_tensor(pn)\n",
        "    df.draw_image(pixels, (0, 0))\n",
        "    image = PIL.Image.open(pn)\n",
        "    # ensure_fine_tuning_directory_exists()\n",
        "    Path(fine_tuning_directory).mkdir(exist_ok=True)\n",
        "    image.save(fine_tuning_directory + \"test.png\")\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220428 \n",
        "\n",
        "# test()\n",
        "\n",
        "clean_up_communication_directory()\n",
        "restart_run()\n",
        "\n",
        "################################################################################"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EvoCamoVsLearningPredator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}