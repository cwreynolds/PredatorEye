{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evo_Camo_vs_Static_FCD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "g8AbtMQfMUkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr9fUxZxJBRl",
        "outputId": "31a674da-e0d6-4cd8-9eea-9a24d8653856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.7.0\n"
          ]
        }
      ],
      "source": [
        "# Shared \"communication\" directory on Drive.\n",
        "shared_directory = '/content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/'\n",
        "\n",
        "# trained_model = '/content/drive/My Drive/PredatorEye/saved_models/20211220_1404'\n",
        "# trained_model = '/content/drive/My Drive/PredatorEye/saved_models/20211222_1044'\n",
        "# use fresh copy on Jan 1: 20220101_0954\n",
        "# trained_model = '/content/drive/My Drive/PredatorEye/saved_models/20220101_0954'\n",
        "\n",
        "saved_model_directory = '/content/drive/My Drive/PredatorEye/saved_models/'\n",
        "trained_model = saved_model_directory + '20220202_1211_Find_3_Disks_complex'\n",
        "model = []\n",
        "\n",
        "my_prefix = \"find_\"\n",
        "other_prefix = \"camo_\"\n",
        "\n",
        "my_suffix =  \".txt\"\n",
        "other_suffix = \".jpeg\"\n",
        "\n",
        "fcd_image_size = 1024\n",
        "fcd_disk_size = 201\n",
        "\n",
        "import time\n",
        "import PIL\n",
        "from os import listdir\n",
        "from os import remove\n",
        "from os.path import join\n",
        "from os.path import split\n",
        "from os.path import isfile\n",
        "from tensorflow import keras\n",
        "\n",
        "# from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')\n",
        "\n",
        "# Import DiskFind utilities for PredatorEye.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
        "import DiskFind as df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After c++ tests"
      ],
      "metadata": {
        "id": "jCxVUKpMTEcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_test():\n",
        "    print('Start run in', shared_directory )\n",
        "    list_unexpected_files(shared_directory)\n",
        "    step = 0;\n",
        "    while True:\n",
        "        performStep(step, shared_directory)\n",
        "        step += 1\n",
        "\n",
        "def performStep(step, directory):\n",
        "    waitForReply(step, shared_directory)\n",
        "    print('Write file', step)\n",
        "    writeTestFile(step, shared_directory)\n",
        "    deleteMyFile(step - 1, shared_directory)\n",
        "\n",
        "# TODO 20220203 this is no longer the \"mock\"/\"test\" version of this function.\n",
        "# Mock version of writing file for given step.\n",
        "def writeTestFile(step, directory):\n",
        "    pathname = makeMyPathname(step, directory)\n",
        "    file = open(pathname,\"w\")\n",
        "    #\n",
        "    # file.write(str(step))\n",
        "    # file.write(str(step) + \" \" + str(step))\n",
        "\n",
        "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
        "\n",
        "    # image = Image.open(makeOtherPathname(step, directory))\n",
        "    # # new_size = (fcd_image_size, fcd_image_size)\n",
        "    # # pixels = asarray(image.resize(new_size, PIL.Image.LANCZOS),\n",
        "    # #                     dtype=np.float32)        \n",
        "    # pixel_tensor = np.asarray(image, dtype=np.float32)\n",
        "    \n",
        "\n",
        "\n",
        "    # 20220203 copied from make_complex_example() in Find_3_Disks\n",
        "    # maybe should move to FindDisk.py?\n",
        "\n",
        "    # # Read image file.\n",
        "    # # image = PIL.Image.open(image_pathname)\n",
        "    # image = PIL.Image.open(makeOtherPathname(step, directory))\n",
        "    # # Convert to numpy pixel tensor as 32 bit floats.\n",
        "    # # pixels = np.asarray(image, dtype=np.float32)\n",
        "    # pixel_tensor = np.asarray(image, dtype=np.float32)\n",
        "    # # Scale input image data to range [0, 1]\n",
        "    # # TODO try the experiment of using range [-1, 1] as was used in DLAVA\n",
        "    # # pixels = np.interp(pixels, [0, 255], [0, 1]).astype(np.float32)\n",
        "    # pixel_tensor = np.interp(pixel_tensor, [0, 255], [0, 1]).astype(np.float32)\n",
        "\n",
        "    # Read image file.\n",
        "    image_pathname = makeOtherPathname(step, directory)\n",
        "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "\n",
        "\n",
        "    # print('-------------------------------------------------------------------')\n",
        "    # print('pixel_tensor.shape =', pixel_tensor.shape)\n",
        "    # print('np.min(pixel_tensor) =', np.min(pixel_tensor))\n",
        "    # print('np.max(pixel_tensor) =', np.max(pixel_tensor))\n",
        "    # print('-------------------------------------------------------------------')\n",
        "\n",
        "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
        "\n",
        "    predict = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "    x = predict[0]\n",
        "    y = predict[1]\n",
        "    # print(i, \": (\", x, \",\", y, \")\")\n",
        "    #\n",
        "    # image_size = 128 # temp, derive from data\n",
        "    # file.write(str(x * image_size) + \" \" + str(y * image_size))\n",
        "    #\n",
        "    response_string = str(x) + \" \" + str(y)\n",
        "    # print('response_string', response_string)\n",
        "    # print('x =', x, ', y =', y, ', response_string =', response_string)\n",
        "    # print('response_string' + \"'\" + response_string + \"'\")\n",
        "    print('response_string ' + \"'\" + response_string + \"'\")\n",
        "    file.write(response_string)\n",
        "    file.close()\n",
        "    #\n",
        "    print(\"wrote test file  \", makeMyPathname(step, directory))\n",
        "\n",
        "# Delete the given file, usually after having written the next one.\n",
        "def deleteMyFile(step, directory):\n",
        "    path = makeMyPathname(step, directory)\n",
        "    if isfile(path):\n",
        "        remove(path)\n",
        "\n",
        "# Form pathname for file of given step number from the \"other\" agent.\n",
        "def makeOtherPathname(step, directory):\n",
        "    return directory + other_prefix + str(step) + other_suffix\n",
        "\n",
        "# Form pathname for file of given step number from \"this\" agent.\n",
        "def makeMyPathname(step, directory):\n",
        "    return directory + my_prefix + str(step) + my_suffix\n",
        "\n",
        "# Wait until other agent's file for given step appears.\n",
        "def waitForReply(step, directory):\n",
        "    print('start waiting for', makeOtherPathname(step, directory))\n",
        "    start_time = time.time()\n",
        "    while not isFilePresent(makeOtherPathname(step, directory)):\n",
        "        time.sleep(2)  # wait 2 sec\n",
        "    print('done waiting for ', makeOtherPathname(step, directory))\n",
        "    print('Elapsed time:', int(time.time() - start_time), 'seconds.')\n",
        "\n",
        "# Like fs::exists() but for unknown reasons, that does not\n",
        "# seem to work for newly created files on G Drive.\n",
        "#\n",
        "# TODO Why? This version works on G Drive, but it seems simply\n",
        "#      calling fs::exists() should be enough.\n",
        "#\n",
        "def isFilePresent(file):\n",
        "    result = False\n",
        "    (directory, filename) = split(file)\n",
        "    for i in listdir(directory):\n",
        "        if i == filename:\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "# isFilePresent(comm_directory + 'foo.txt')\n",
        "# isFilePresent(comm_directory + 'bar.txt')\n",
        "# waitForReply(1, comm_directory)\n",
        "\n",
        "# Actually I guess the counterparty may have already written its first...\n",
        "def list_unexpected_files(directory):\n",
        "    directory_contents = listdir(directory)\n",
        "    if directory_contents:\n",
        "        print('Unexpected files:', directory_contents)"
      ],
      "metadata": {
        "id": "ZF4XLFSBTKOM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read pre-trained model"
      ],
      "metadata": {
        "id": "VDtbk88sVGxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read model\n",
        "\n",
        "print('Reading pre-trained model from:', trained_model)\n",
        "# model = keras.models.load_model(trained_model)\n",
        "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
        "\n",
        "# dependencies = {\n",
        "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
        "#     'attention': attention(return_sequences=True)\n",
        "# }\n",
        "\n",
        "# dependencies = {\n",
        "#     'valid_accuracy': ValidAccuracy\n",
        "# }\n",
        "\n",
        "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
        "def fcd_disk_radius():\n",
        "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
        "# distance between corresponding points in the input tensors.\n",
        "def corresponding_distances(y_true, y_pred):\n",
        "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
        "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
        "    dx = true_pos_x - pred_pos_x\n",
        "    dy = true_pos_y - pred_pos_y\n",
        "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
        "    return distances\n",
        "\n",
        "# 20211231 copied from Find_Concpocuous_Disk\n",
        "def in_disk(y_true, y_pred):\n",
        "    distances = corresponding_distances(y_true, y_pred)\n",
        "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "    # From https://stackoverflow.com/a/42450565/1991373\n",
        "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
        "    # insides = tf.less(distances, relative_disk_radius)\n",
        "    insides = tf.less(distances, fcd_disk_radius())\n",
        "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
        "    return map_to_zero_or_one\n",
        "\n",
        "dependencies = { 'in_disk': in_disk }\n",
        "\n",
        "# 20220101 can I now compile the reloaded model?\n",
        "# model = keras.models.load_model(trained_model,\n",
        "#                                 custom_objects=dependencies,\n",
        "#                                 compile=False)\n",
        "model = keras.models.load_model(trained_model, custom_objects=dependencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLVIRi_vU9gN",
        "outputId": "2bc1e011-5b83-4eb4-d0b0-bf6006a73faf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pre-trained model from: /content/drive/My Drive/PredatorEye/saved_models/20220202_1211_Find_3_Disks_complex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run test"
      ],
      "metadata": {
        "id": "itBD_Ve0lEYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "iZQLL52Sk-X9",
        "outputId": "4d5a5846-867c-43e4-eafa-0d7a12ff2597"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start run in /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "Unexpected files: ['find_1663.txt', 'camo_1664.jpeg', 'camo_0.jpeg']\n",
            "start waiting for /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_0.jpeg\n",
            "done waiting for  /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_0.jpeg\n",
            "Elapsed time: 0 seconds.\n",
            "Write file 0\n",
            "response_string '0.43781003 0.2711767'\n",
            "wrote test file   /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/find_0.txt\n",
            "start waiting for /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_1.jpeg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5e0b864b2c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-6d182450794b>\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mperformStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6d182450794b>\u001b[0m in \u001b[0;36mperformStep\u001b[0;34m(step, directory)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperformStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwaitForReply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Write file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwriteTestFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6d182450794b>\u001b[0m in \u001b[0;36mwaitForReply\u001b[0;34m(step, directory)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misFilePresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmakeOtherPathname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait 2 sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done waiting for '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmakeOtherPathname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Elapsed time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}