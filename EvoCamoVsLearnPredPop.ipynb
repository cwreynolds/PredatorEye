{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8AbtMQfMUkt"
   },
   "source": [
    "# Evolutionary Camouflage Versus a Learning Predator Population\n",
    "\n",
    "---\n",
    "\n",
    "EvoCamoVsLearnPredPop.ipynb\n",
    "\n",
    "Just a copy of EvoCamoVsLearningPredator.ipynb as of 20220607\n",
    "\n",
    "On 20220716 starting from here to prototype “local” version running on my Apple Silicon M1 laptop. Got as far as trying to read pre-tained “FCD6_rc4” model but it complained it was compiled for Intel, while this is Apple Silicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cr9fUxZxJBRl",
    "outputId": "80ad75fe-c5b6-4c3c-9612-606b391f1a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# # Shared \"communication\" directory on Drive.\n",
    "# shared_directory = '/content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/'\n",
    "\n",
    "# # Pathname of pre-trained Keras/TensorFlow model\n",
    "# saved_model_directory = '/content/drive/My Drive/PredatorEye/saved_models/'\n",
    "\n",
    "# PredatorEye directory on Drive.\n",
    "pe_directory = '/content/drive/My Drive/PredatorEye/'\n",
    "\n",
    "##################################################################################\n",
    "# TODO 20220716 -- work toward \"local\" version on M1 laptop (no GPU yet)\n",
    "# Shared \"communication\" (\"comms\") directory on Drive.\n",
    "# shared_directory = '/content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/'\n",
    "# shared_directory = pe_directory + 'evo_camo_vs_static_fcd/'\n",
    "\n",
    "# not sure where to put this, or if it deserves to be top level of my home dir\n",
    "shared_directory = '/Users/cwr/comms/'\n",
    "\n",
    "# Directory for pre-trained Keras/TensorFlow models on Drive.\n",
    "# saved_model_directory = '/content/drive/My Drive/PredatorEye/saved_models/'\n",
    "# saved_model_directory = pe_directory + 'saved_models/'\n",
    "\n",
    "g_drive_pe_dir = ('/Users/cwr/Library/CloudStorage/' +\n",
    "                  'GoogleDrive-craig.w.reynolds@gmail.com/' +\n",
    "                  'My Drive/PredatorEye/')\n",
    "saved_model_directory = g_drive_pe_dir + 'saved_models/'\n",
    "##################################################################################\n",
    "\n",
    "# Pathname of pre-trained Keras/TensorFlow model\n",
    "# trained_model = saved_model_directory + '20220202_1211_Find_3_Disks_complex'\n",
    "# trained_model = saved_model_directory + '20220222_1747_F3D_augmented_rc4'\n",
    "# trained_model = saved_model_directory + '20220227_0746_F3D2_a'\n",
    "# trained_model = saved_model_directory + '20220304_1135_FCD5_a'\n",
    "trained_model = saved_model_directory + '20220321_1711_FCD6_rc4'\n",
    "model = []\n",
    "\n",
    "# Directory on Drive for storing fine-tuning dataset.\n",
    "fine_tuning_directory = shared_directory + 'fine_tuning/'\n",
    "\n",
    "my_prefix = \"find_\"\n",
    "other_prefix = \"camo_\"\n",
    "\n",
    "my_suffix =  \".txt\"\n",
    "# other_suffix = \".jpeg\"\n",
    "other_suffix = \".png\"\n",
    "\n",
    "fcd_image_size = 1024\n",
    "fcd_disk_size = 201\n",
    "\n",
    "import time\n",
    "import PIL\n",
    "################################################################################\n",
    "# TODO 20220420\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Came upon Python 3's 'pathlib' https://docs.python.org/3/library/pathlib.html\n",
    "# while fixing a bug. I think the API below is obsolete and should be replaced.\n",
    "from os import listdir\n",
    "# from os import remove\n",
    "# from os.path import join\n",
    "from os.path import split\n",
    "# from os.path import isfile\n",
    "################################################################################\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "keras_backend.set_image_data_format('channels_last')\n",
    "\n",
    "# Import DiskFind utilities for PredatorEye.\n",
    "import sys\n",
    "##################################################################################\n",
    "# TODO 20220716 -- work toward \"local\" version on M1 laptop (no GPU yet)\n",
    "# sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
    "\n",
    "# TODO 20220716 -- writing this inline seems unartful:\n",
    "sys.path.append('/Users/cwr/Documents/code/PredatorEye/')\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "import DiskFind as df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCxVUKpMTEcN"
   },
   "source": [
    "# Ad hoc “predator server”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZF4XLFSBTKOM"
   },
   "outputs": [],
   "source": [
    "# Top level: wait for camo_xxx.jpeg files to appear, respond with find_xxx.txt\n",
    "def start_run(step = 0):\n",
    "    if step == 0:\n",
    "        print('Start run in', shared_directory )\n",
    "        list_unexpected_files(shared_directory)\n",
    "    else:\n",
    "        print('Continue run at step', step, ' in', shared_directory)\n",
    "    while True:\n",
    "        perform_step(step, shared_directory)\n",
    "        step += 1\n",
    "\n",
    "# Continue from from the last camo_xxx.jpeg file.\n",
    "def restart_run():\n",
    "    start_run(newest_file_from_other(shared_directory))\n",
    "\n",
    "# Single step: wait for camo file, write response, delete previous response.\n",
    "def perform_step(step, directory):\n",
    "    wait_for_reply(step, shared_directory)\n",
    "    write_response_file(step, shared_directory)\n",
    "    delete_find_file(step - 1, shared_directory)\n",
    "\n",
    "# Read image file for step, apply pre-trained model, write response file.\n",
    "def write_response_file(step, directory):\n",
    "    # Read image file and check for expected format.\n",
    "    image_pathname = make_camo_pathname(step, directory)\n",
    "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
    "    assert df.check_pixel_tensor(pixel_tensor), ('wrong file format: ' +\n",
    "                                                 image_pathname)\n",
    "    # Run pre-trained model on new image.\n",
    "    prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
    "    # Generate response file.\n",
    "    response_string = str(prediction[0]) + \" \" + str(prediction[1])\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(make_find_pathname(step, directory), 'w') as file:\n",
    "        file.write(response_string)\n",
    "    print('Wrote ' + \"'\" + response_string + \"'\",\n",
    "          'to response file', Path(make_find_pathname(step, directory)).name)\n",
    "    # Predator learns from recent experience.\n",
    "    fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
    "\n",
    "# Delete the given file, usually after having written the next one.\n",
    "def delete_find_file(step, directory):\n",
    "    # Why doesn't pathlib provide a Path.remove() method like os?\n",
    "    # TODO oh, missing_ok was added at pathlib version 3.8.\n",
    "    # Path(makeMyPathname(step, directory)).unlink(missing_ok=True)\n",
    "    p = Path(make_find_pathname(step, directory))\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "\n",
    "# Delete any remaining file in commuications directory to start a new run.\n",
    "def clean_up_communication_directory():\n",
    "    def delete_directory_contents(directory_path):\n",
    "        for path in directory_path.iterdir():\n",
    "            print('Removing from communication directory:', path)\n",
    "            if path.is_dir():\n",
    "                delete_directory_contents(path)\n",
    "                path.rmdir()\n",
    "            else:\n",
    "                path.unlink()\n",
    "    delete_directory_contents(Path(shared_directory))\n",
    "\n",
    "# From pathname for file of given step number from the \"other\" agent.\n",
    "def make_camo_pathname(step, directory):\n",
    "    return directory + other_prefix + str(step) + other_suffix\n",
    "\n",
    "# Form pathname for \"find_xx.txt\" response file from \"this\" agent.\n",
    "def make_find_pathname(step, directory):\n",
    "    return directory + my_prefix + str(step) + my_suffix\n",
    "\n",
    "# Form pathname for \"prey_xx.txt\" ground truth file from \"other\" agent.\n",
    "def make_prey_pathname(step, directory):\n",
    "    return directory + 'prey_' + str(step) + '.txt'\n",
    "\n",
    "# Used to ping the comms directory when it seems hung.\n",
    "def write_ping_file(count, step, directory):\n",
    "    pn = directory + 'ping_cloud_' + str(step) + '.txt'\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(pn, 'w') as file:\n",
    "        file.write(str(count))\n",
    "    print('Ping comms: ', count, pn)\n",
    "\n",
    "# Wait until other agent's file for given step appears.\n",
    "def wait_for_reply(step, directory):\n",
    "    camo_pathname = Path(make_camo_pathname(step, directory))\n",
    "    camo_filename = camo_pathname.name\n",
    "    prey_pathname = Path(make_prey_pathname(step, directory))\n",
    "    prey_filename = prey_pathname.name\n",
    "    print('Waiting for', camo_filename, 'and', prey_filename, '...',\n",
    "          end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    # Loop until both files are present, waiting 1 second between tests.\n",
    "    test_count = 0\n",
    "    while not (is_file_present(camo_pathname) and\n",
    "               is_file_present(prey_pathname)):\n",
    "        time.sleep(1)\n",
    "        test_count += 1\n",
    "        if (test_count % 100) == 0:\n",
    "            write_ping_file(test_count, step, directory)\n",
    "    print(' done, elapsed time:', int(time.time() - start_time), 'seconds.')\n",
    "\n",
    "# Like fs::exists()\n",
    "def is_file_present(file):\n",
    "    result = False\n",
    "    verify_comms_directory_reachable()\n",
    "    (directory, filename) = split(file)\n",
    "    for i in listdir(directory):\n",
    "        if i == filename:\n",
    "            result = True\n",
    "    return result\n",
    "\n",
    "# Actually I guess the counterparty may have already written its first...\n",
    "def list_unexpected_files(directory):\n",
    "    directory_contents = listdir(directory)\n",
    "    if directory_contents:\n",
    "        print('Unexpected files:', directory_contents)\n",
    "\n",
    "# Returns the step number of the newest file from \"other\" in given directory.\n",
    "# (So if \"camo_573.jpeg\" is the only \"other\" file there, returns int 573)\n",
    "def newest_file_from_other(directory):\n",
    "    steps = [0]  # Default to zero in case dir is empty.\n",
    "    for filename in listdir(directory):\n",
    "        if other_prefix == filename[0:len(other_prefix)]:\n",
    "            steps.append(int(filename.split(\".\")[0].split(\"_\")[1]))\n",
    "    return max(steps)\n",
    "\n",
    "# Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
    "# https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
    "# of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
    "# max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
    "max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
    "# List of \"pixel tensors\".\n",
    "fine_tune_images = []\n",
    "# List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
    "fine_tune_labels = []\n",
    "\n",
    "################################################################################\n",
    "# TODO 20220517 keep track of how often selected prey is nearest center:\n",
    "nearest_center = 0\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
    "# training set. Assume they were \"near misses\" and so training label is actual\n",
    "# (ground truth) center of disk nearest prediction. Keep a max number of old\n",
    "# steps to allow gradually forgetting the earliest part of the run.\n",
    "def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
    "    # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
    "    xy3 = read_3_centers_from_file(step, directory)\n",
    "    sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
    "\n",
    "    # Accumulate the most recent \"max_training_set_size\" training samples.\n",
    "    global fine_tune_images\n",
    "    global fine_tune_labels\n",
    "    fine_tune_images.append(pixel_tensor)\n",
    "    fine_tune_labels.append(sorted_xy3)\n",
    "\n",
    "    # If training set has become too large, slice off first element of each.\n",
    "    if len(fine_tune_images) > max_training_set_size:\n",
    "        fine_tune_images = fine_tune_images[1:]\n",
    "        fine_tune_labels = fine_tune_labels[1:]\n",
    "\n",
    "    # keep track of how often selected prey is nearest center:\n",
    "    temp = xy3.copy()  # needed?\n",
    "    sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
    "    if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
    "        global nearest_center\n",
    "        nearest_center += 1\n",
    "    print('  nearest_center:',\n",
    "          str(int(100 * float(nearest_center) / (step + 1))) + '%',\n",
    "          '(nearest_center =', nearest_center, ', steps =', step + 1, ')')\n",
    "\n",
    "    # Convert training data list to np arrays\n",
    "    images_array = np.array(fine_tune_images)\n",
    "    labels_array = np.array([x[0] for x in fine_tune_labels])\n",
    "    print('images_array.shape =', images_array.shape)\n",
    "    print('labels_array.shape =', labels_array.shape)\n",
    "\n",
    "\t# skip fine-tuning until dataset is large enough (10% of max size).\n",
    "    if images_array.shape[0] > (max_training_set_size * 0.1):\n",
    "        # Do fine-tuning training step using data accumulated during run.\n",
    "        history = model.fit(x=images_array, y=labels_array)\n",
    "        # Keep log of in_disk metric:\n",
    "        write_in_disk_log(step, history)\n",
    "\n",
    "# Read ground truth prey center location data provided in \"prey_n.txt\" file.\n",
    "def read_3_centers_from_file(step, directory):\n",
    "    # Read contents of file as string.\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(make_prey_pathname(step, directory), 'r') as file:\n",
    "        prey_centers_string = file.read()\n",
    "    # Split string at whitespace, map to 6 floats, reshape into 3 xy pairs.\n",
    "    # (TODO could probably be rewritten cleaner with \"list comprehension\")\n",
    "    array = np.reshape(list(map(float, prey_centers_string.split())), (3, 2))\n",
    "    return array.tolist()\n",
    "\n",
    "# Keep log of in_disk metric.\n",
    "def write_in_disk_log(step, history):\n",
    "    if step % 10 == 0:\n",
    "        in_disk = history.history[\"in_disk\"][0]\n",
    "        pathname = shared_directory + 'in_disk_log.csv'\n",
    "        verify_comms_directory_reachable()\n",
    "        with open(pathname, 'a') as file:\n",
    "            if step == 0:\n",
    "                file.write('step,in_disk\\n')\n",
    "            file.write(str(step) + ',' + \"{:.4f}\".format(in_disk) + '\\n')\n",
    "\n",
    "# Just wait in retry loop if shared \"comms\" directory become unreachable.\n",
    "# Probably will return shortly, better to wait than signal a file error.\n",
    "# (This is called from places with a local \"directory\" but it uses global value.)\n",
    "def verify_comms_directory_reachable():\n",
    "    seconds = 0\n",
    "    # shared_directory_pathname = Path(shared_directory)\n",
    "    # while not shared_directory_pathname.is_dir():\n",
    "    while not Path(shared_directory).is_dir():\n",
    "        print(\"Shared “comms” directory,\", shared_directory, \n",
    "              \"has been inaccessible for\", seconds, \"seconds.\")\n",
    "        time.sleep(1)  # wait 1 sec\n",
    "        seconds += 1\n",
    "\n",
    "# Given 3 prey positions (\"xy3\"), sort them by proximity to \"point\" (prediction)\n",
    "def sort_xy3_by_proximity_to_point(xy3, point):\n",
    "    # print('xy3 =', xy3)\n",
    "    xy3_plus_distance = [[df.dist2d(xy, point), xy] for xy in xy3]\n",
    "    # print('xy3_plus_distance =', xy3_plus_distance)\n",
    "    sorted_xy3_plus_key = sorted(xy3_plus_distance, key=lambda x: x[0])\n",
    "    # print('sorted_xy3_plus_key =', sorted_xy3_plus_key)\n",
    "    sorted_xy3 = [x[1] for x in sorted_xy3_plus_key]\n",
    "    # print('sorted_xy3 =', sorted_xy3)\n",
    "    return sorted_xy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDtbk88sVGxk"
   },
   "source": [
    "# Read pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLVIRi_vU9gN",
    "outputId": "019de0f2-95b2-4264-cd4d-01bbdf73a382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pre-trained model from: /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 11:55:27.192938: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 11:55:27.194034: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6_/y2_08drc8xjf5n00r6_tfw380000gn/T/ipykernel_78917/2249042454.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'in_disk'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0min_disk\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;31m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRevivedModel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    539\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[1;32m    540\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                           export_dir)\n\u001b[0m\u001b[1;32m    542\u001b[0m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WrapperFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m# TODO(b/124045874): There are limitations with functions whose captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# trigger other functions to be executed. For now it is only guaranteed to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m_load_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# interface.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mnode_setters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m_recreate\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown SavedObject type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_recreate_user_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m\"\"\"Creates a Python object from a SavedObject protocol buffer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     factory = {\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;34m\"user_object\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_user_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;34m\"asset\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_asset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;34m\"function\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m_recreate_user_object\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mlooked_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevived_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlooked_up\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_base_user_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlooked_up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_recreate_base_user_object\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparent_classes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mparent_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevived_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m       \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m       revived_cls = type(\n\u001b[1;32m    177\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/camouflage/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Read pre-trained TensorFlow \"predator vision\" model.\n",
    "\n",
    "print('Reading pre-trained model from:', trained_model)\n",
    "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
    "#\n",
    "# dependencies = {\n",
    "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
    "#     'attention': attention(return_sequences=True)\n",
    "# }\n",
    "#\n",
    "# dependencies = {\n",
    "#     'valid_accuracy': ValidAccuracy\n",
    "# }\n",
    "\n",
    "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
    "def fcd_disk_radius():\n",
    "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
    "\n",
    "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
    "# distance between corresponding points in the input tensors.\n",
    "def corresponding_distances(y_true, y_pred):\n",
    "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
    "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
    "    dx = true_pos_x - pred_pos_x\n",
    "    dy = true_pos_y - pred_pos_y\n",
    "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
    "    return distances\n",
    "\n",
    "# 20211231 copied from Find_Concpocuous_Disk\n",
    "def in_disk(y_true, y_pred):\n",
    "    distances = corresponding_distances(y_true, y_pred)\n",
    "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
    "\n",
    "    # From https://stackoverflow.com/a/42450565/1991373\n",
    "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
    "    # insides = tf.less(distances, relative_disk_radius)\n",
    "    insides = tf.less(distances, fcd_disk_radius())\n",
    "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
    "    return map_to_zero_or_one\n",
    "\n",
    "dependencies = { 'in_disk': in_disk }\n",
    "\n",
    "model = keras.models.load_model(trained_model, custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itBD_Ve0lEYB"
   },
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "iZQLL52Sk-X9",
    "outputId": "25177e45-f1f3-4d42-d6cf-66ab3fffb7cf"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO 20220517 keep track of how often selected prey is nearest center:\n",
    "nearest_center = 0\n",
    "################################################################################\n",
    "\n",
    "clean_up_communication_directory()\n",
    "start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h7-m6IIu6i4"
   },
   "outputs": [],
   "source": [
    "# Normally start from step 0, or if an \"other\" file exists\n",
    "# (eg 'camo_123.jpeg') then restart from that point.\n",
    "\n",
    "# restart_run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EvoCamoVsLearnPredPop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
