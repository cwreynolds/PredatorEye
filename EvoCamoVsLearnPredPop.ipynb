{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvoCamoVsLearnPredPop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8AbtMQfMUkt"
      },
      "source": [
        "# Evolutionary Camouflage Versus a Learning Predator Population\n",
        "\n",
        "---\n",
        "\n",
        "EvoCamoVsLearnPredPop.ipynb\n",
        "\n",
        "Started as a copy of EvoCamoVsLearningPredator.ipynb as of 20220607\n",
        "\n",
        "On 20220716 starting from here to prototype “local” version running on my Apple Silicon M1 laptop. Got as far as trying to read pre-tained “FCD6_rc4” model but it complained it was compiled for Intel, while this is Apple Silicon.\n",
        "\n",
        "OK now on 20220722 I am converting this back to \"Rube Goldberg\" mode where predator vision happens in the cloud, and camouflage evolution runs on my laptop. I tried using the [TensorFlow-Metal plugin](https://developer.apple.com/metal/tensorflow-plugin/), but ran into a [bug](https://developer.apple.com/forums/thread/706920). Until that is fixed I will fall back to the old half-cloud-half-laptop approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr9fUxZxJBRl",
        "outputId": "e91f0439-d498-47af-ef26-3d6ff6857c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rube_Goldberg_mode = True\n",
            "shared_directory = /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "saved_model_directory = /content/drive/My Drive/PredatorEye/saved_models/\n",
            "TensorFlow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "# \"Rube Goldberg\" mode refers to running camouflage evolution on my laptop while\n",
        "# running predator vision in cloud via Colab. State is passed back and forth via\n",
        "# files on Google Drive.\n",
        "Rube_Goldberg_mode = True\n",
        "def if_RG_mode(for_RG_mode, for_normal_mode):\n",
        "    return for_RG_mode if Rube_Goldberg_mode else for_normal_mode\n",
        "\n",
        "# PredatorEye directory on Drive.\n",
        "pe_directory = '/content/drive/My Drive/PredatorEye/'\n",
        "\n",
        "# Shared \"communication\" directory on Drive.\n",
        "shared_directory = if_RG_mode(pe_directory + 'evo_camo_vs_static_fcd/',\n",
        "                              '/Users/cwr/comms/')\n",
        "\n",
        "# This was meant (20220716) to allow reading original pre-trained model from\n",
        "# Google Drive, but I'll need to retrain it for M1 (Apple Silicon).\n",
        "g_drive_pe_dir = ('/Users/cwr/Library/CloudStorage/' +\n",
        "                  'GoogleDrive-craig.w.reynolds@gmail.com/' +\n",
        "                  'My Drive/PredatorEye/')\n",
        "\n",
        "# Directory for pre-trained Keras/TensorFlow models.\n",
        "saved_model_directory = if_RG_mode(pe_directory, g_drive_pe_dir) + 'saved_models/'\n",
        "\n",
        "\n",
        "print('Rube_Goldberg_mode =', Rube_Goldberg_mode)\n",
        "print('shared_directory =', shared_directory)\n",
        "print('saved_model_directory =', saved_model_directory)\n",
        "\n",
        "# Pathname of pre-trained Keras/TensorFlow model\n",
        "# trained_model = saved_model_directory + '20220202_1211_Find_3_Disks_complex'\n",
        "# trained_model = saved_model_directory + '20220222_1747_F3D_augmented_rc4'\n",
        "# trained_model = saved_model_directory + '20220227_0746_F3D2_a'\n",
        "# trained_model = saved_model_directory + '20220304_1135_FCD5_a'\n",
        "trained_model = saved_model_directory + '20220321_1711_FCD6_rc4'\n",
        "# model = []\n",
        "\n",
        "# Directory on Drive for storing fine-tuning dataset.\n",
        "fine_tuning_directory = shared_directory + 'fine_tuning/'\n",
        "\n",
        "my_prefix = \"find_\"\n",
        "other_prefix = \"camo_\"\n",
        "\n",
        "my_suffix =  \".txt\"\n",
        "# other_suffix = \".jpeg\"\n",
        "other_suffix = \".png\"\n",
        "\n",
        "fcd_image_size = 1024\n",
        "fcd_disk_size = 201\n",
        "\n",
        "import time\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')\n",
        "\n",
        "# Import DiskFind utilities for PredatorEye.\n",
        "import sys\n",
        "if Rube_Goldberg_mode:\n",
        "    sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
        "else:\n",
        "    sys.path.append('/Users/cwr/Documents/code/PredatorEye/')\n",
        "import DiskFind as df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCxVUKpMTEcN"
      },
      "source": [
        "# Ad hoc “predator server”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZF4XLFSBTKOM"
      },
      "outputs": [],
      "source": [
        "# Top level: wait for camo_xxx.jpeg files to appear, respond with find_xxx.txt\n",
        "def start_run(step = 0):\n",
        "    if step == 0:\n",
        "        print('Start run in', shared_directory )\n",
        "    else:\n",
        "        print('Continue run at step', step, ' in', shared_directory)\n",
        "    while True:\n",
        "        perform_step(step, shared_directory)\n",
        "        step += 1\n",
        "\n",
        "# Continue from from the last camo_xxx.jpeg file.\n",
        "def restart_run():\n",
        "    start_run(newest_file_from_other(shared_directory))\n",
        "\n",
        "# Single step: wait for camo file, write response, delete previous response.\n",
        "def perform_step(step, directory):\n",
        "    wait_for_reply(step, shared_directory)\n",
        "    write_response_file(step, shared_directory)\n",
        "    delete_find_file(step - 1, shared_directory)\n",
        "\n",
        "# Read image file for step, apply pre-trained model, write response file.\n",
        "def write_response_file(step, directory):\n",
        "    # Read image file and check for expected format.\n",
        "    image_pathname = make_camo_pathname(step, directory)\n",
        "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "    assert df.check_pixel_tensor(pixel_tensor), ('wrong file format: ' +\n",
        "                                                 image_pathname)\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "\n",
        "    # model = Predator.get_population()[0]\n",
        "    # model = Predator.population[0]\n",
        "    # default_predator = population_of_predators[0]\n",
        "    default_predator = Predator.population[0]\n",
        "    model = default_predator.model\n",
        "\n",
        "    # Run pre-trained model on new image.\n",
        "    prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "    ############################################################################\n",
        "    # Generate response file.\n",
        "    response_string = str(prediction[0]) + \" \" + str(prediction[1])\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(make_find_pathname(step, directory), 'w') as file:\n",
        "        file.write(response_string)\n",
        "    print('Wrote ' + \"'\" + response_string + \"'\",\n",
        "          'to response file', Path(make_find_pathname(step, directory)).name)\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "\n",
        "    # Predator learns from recent experience.\n",
        "    # fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
        "    default_predator.fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
        "    ############################################################################\n",
        "\n",
        "# Delete the given file, usually after having written the next one.\n",
        "def delete_find_file(step, directory):\n",
        "    # Why doesn't pathlib provide a Path.remove() method like os?\n",
        "    # TODO oh, missing_ok was added at pathlib version 3.8.\n",
        "    # Path(makeMyPathname(step, directory)).unlink(missing_ok=True)\n",
        "    p = Path(make_find_pathname(step, directory))\n",
        "    if p.exists():\n",
        "        p.unlink()\n",
        "\n",
        "# Delete any remaining file in commuications directory to start a new run.\n",
        "def clean_up_communication_directory():\n",
        "    def delete_directory_contents(directory_path):\n",
        "        for path in directory_path.iterdir():\n",
        "            print('Removing from communication directory:', path)\n",
        "            if path.is_dir():\n",
        "                delete_directory_contents(path)\n",
        "                path.rmdir()\n",
        "            else:\n",
        "                path.unlink()\n",
        "    delete_directory_contents(Path(shared_directory))\n",
        "\n",
        "# From pathname for file of given step number from the \"other\" agent.\n",
        "def make_camo_pathname(step, directory):\n",
        "    return directory + other_prefix + str(step) + other_suffix\n",
        "\n",
        "# Form pathname for \"find_xx.txt\" response file from \"this\" agent.\n",
        "def make_find_pathname(step, directory):\n",
        "    return directory + my_prefix + str(step) + my_suffix\n",
        "\n",
        "# Form pathname for \"prey_xx.txt\" ground truth file from \"other\" agent.\n",
        "def make_prey_pathname(step, directory):\n",
        "    return directory + 'prey_' + str(step) + '.txt'\n",
        "\n",
        "# Used to ping the comms directory when it seems hung.\n",
        "def write_ping_file(count, step, directory):\n",
        "    pn = directory + 'ping_cloud_' + str(step) + '.txt'\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(pn, 'w') as file:\n",
        "        file.write(str(count))\n",
        "    print('Ping comms: ', count, pn)\n",
        "\n",
        "# Wait until other agent's file for given step appears.\n",
        "def wait_for_reply(step, directory):\n",
        "    camo_pathname = Path(make_camo_pathname(step, directory))\n",
        "    camo_filename = camo_pathname.name\n",
        "    prey_pathname = Path(make_prey_pathname(step, directory))\n",
        "    prey_filename = prey_pathname.name\n",
        "    print('Waiting for', camo_filename, 'and', prey_filename, '...',\n",
        "          end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    # Loop until both files are present, waiting 1 second between tests.\n",
        "    test_count = 0\n",
        "    while not (is_file_present(camo_pathname) and\n",
        "               is_file_present(prey_pathname)):\n",
        "        time.sleep(1)\n",
        "        test_count += 1\n",
        "        if (test_count % 100) == 0:\n",
        "            write_ping_file(test_count, step, directory)\n",
        "    print(' done, elapsed time:', int(time.time() - start_time), 'seconds.')\n",
        "\n",
        "# Like fs::exists()\n",
        "def is_file_present(file):\n",
        "    result = False\n",
        "    verify_comms_directory_reachable()\n",
        "    filename = Path(file).name\n",
        "    directory = Path(file).parent\n",
        "    for i in directory.iterdir():\n",
        "        if i.name == filename:\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "# Returns the step number of the newest file from \"other\" in given directory.\n",
        "# (So if \"camo_573.jpeg\" is the only \"other\" file there, returns int 573)\n",
        "def newest_file_from_other(directory):\n",
        "    steps = [0]  # Default to zero in case dir is empty.\n",
        "    for filename in Path(directory).iterdir():\n",
        "        name = filename.name\n",
        "        if other_prefix == name[0:len(other_prefix)]:\n",
        "            steps.append(int(name.split(\".\")[0].split(\"_\")[1]))\n",
        "    return max(steps)\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220728 maybe fine_tune_images, fine_tune_labels, etc. should be\n",
        "# associated with Predator class, but not instance, like c++ class static member.\n",
        "\n",
        "# # Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
        "# # https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
        "# # of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
        "# # max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
        "# max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
        "# # List of \"pixel tensors\".\n",
        "# fine_tune_images = []\n",
        "# # List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
        "# fine_tune_labels = []\n",
        "\n",
        "# # Keep track of how often selected prey is nearest center:\n",
        "# nearest_center = 0\n",
        "\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220728 fine_tune_predator() should become a method of Predator class.\n",
        "\n",
        "# # Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
        "# # training set. Assume they were \"near misses\" and so training label is actual\n",
        "# # (ground truth) center of disk nearest prediction. Keep a max number of old\n",
        "# # steps to allow gradually forgetting the earliest part of the run.\n",
        "# def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
        "#     # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
        "#     xy3 = read_3_centers_from_file(step, directory)\n",
        "#     sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
        "\n",
        "#     # Accumulate the most recent \"max_training_set_size\" training samples.\n",
        "#     global fine_tune_images\n",
        "#     global fine_tune_labels\n",
        "#     fine_tune_images.append(pixel_tensor)\n",
        "#     fine_tune_labels.append(sorted_xy3)\n",
        "\n",
        "#     # If training set has become too large, slice off first element of each.\n",
        "#     if len(fine_tune_images) > max_training_set_size:\n",
        "#         fine_tune_images = fine_tune_images[1:]\n",
        "#         fine_tune_labels = fine_tune_labels[1:]\n",
        "\n",
        "#     # keep track of how often selected prey is nearest center:\n",
        "#     temp = xy3.copy()  # needed?\n",
        "#     sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
        "#     if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
        "#         global nearest_center\n",
        "#         nearest_center += 1\n",
        "#     print('  nearest_center:',\n",
        "#           str(int(100 * float(nearest_center) / (step + 1))) + '%',\n",
        "#           '(nearest_center =', nearest_center, ', steps =', step + 1, ')')\n",
        "\n",
        "#     # Convert training data list to np arrays\n",
        "#     images_array = np.array(fine_tune_images)\n",
        "#     labels_array = np.array([x[0] for x in fine_tune_labels])\n",
        "#     print('images_array.shape =', images_array.shape)\n",
        "#     print('labels_array.shape =', labels_array.shape)\n",
        "\n",
        "# \t# skip fine-tuning until dataset is large enough (10% of max size).\n",
        "#     if images_array.shape[0] > (max_training_set_size * 0.1):\n",
        "#         # Do fine-tuning training step using data accumulated during run.\n",
        "#         history = model.fit(x=images_array, y=labels_array)\n",
        "#         # Keep log of in_disk metric:\n",
        "#         write_in_disk_log(step, history)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# Read ground truth prey center location data provided in \"prey_n.txt\" file.\n",
        "def read_3_centers_from_file(step, directory):\n",
        "    # Read contents of file as string.\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(make_prey_pathname(step, directory), 'r') as file:\n",
        "        prey_centers_string = file.read()\n",
        "    # Split string at whitespace, map to 6 floats, reshape into 3 xy pairs.\n",
        "    # (TODO could probably be rewritten cleaner with \"list comprehension\")\n",
        "    array = np.reshape(list(map(float, prey_centers_string.split())), (3, 2))\n",
        "    return array.tolist()\n",
        "\n",
        "# Keep log of in_disk metric.\n",
        "def write_in_disk_log(step, history):\n",
        "    if step % 10 == 0:\n",
        "        in_disk = history.history[\"in_disk\"][0]\n",
        "        pathname = shared_directory + 'in_disk_log.csv'\n",
        "        verify_comms_directory_reachable()\n",
        "        with open(pathname, 'a') as file:\n",
        "            if step == 0:\n",
        "                file.write('step,in_disk\\n')\n",
        "            file.write(str(step) + ',' + \"{:.4f}\".format(in_disk) + '\\n')\n",
        "\n",
        "# Just wait in retry loop if shared \"comms\" directory become unreachable.\n",
        "# Probably will return shortly, better to wait than signal a file error.\n",
        "# (This is called from places with a local \"directory\" but it uses global value.)\n",
        "def verify_comms_directory_reachable():\n",
        "    seconds = 0\n",
        "    # shared_directory_pathname = Path(shared_directory)\n",
        "    # while not shared_directory_pathname.is_dir():\n",
        "    while not Path(shared_directory).is_dir():\n",
        "        print(\"Shared “comms” directory,\", shared_directory, \n",
        "              \"has been inaccessible for\", seconds, \"seconds.\")\n",
        "        time.sleep(1)  # wait 1 sec\n",
        "        seconds += 1\n",
        "\n",
        "# Given 3 prey positions (\"xy3\"), sort them by proximity to \"point\" (prediction)\n",
        "def sort_xy3_by_proximity_to_point(xy3, point):\n",
        "    # print('xy3 =', xy3)\n",
        "    xy3_plus_distance = [[df.dist2d(xy, point), xy] for xy in xy3]\n",
        "    # print('xy3_plus_distance =', xy3_plus_distance)\n",
        "    sorted_xy3_plus_key = sorted(xy3_plus_distance, key=lambda x: x[0])\n",
        "    # print('sorted_xy3_plus_key =', sorted_xy3_plus_key)\n",
        "    sorted_xy3 = [x[1] for x in sorted_xy3_plus_key]\n",
        "    # print('sorted_xy3 =', sorted_xy3)\n",
        "    return sorted_xy3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDtbk88sVGxk"
      },
      "source": [
        "# Read pre-trained model\n",
        "\n",
        "As I integrate this into the Predator class, this is no longer “Read pre-trained model” but more like “Some utilities for reading the pre-trained model”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iLVIRi_vU9gN"
      },
      "outputs": [],
      "source": [
        "# Read pre-trained TensorFlow \"predator vision\" model.\n",
        "\n",
        "# print('Reading pre-trained model from:', trained_model)\n",
        "\n",
        "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
        "#\n",
        "# dependencies = {\n",
        "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
        "#     'attention': attention(return_sequences=True)\n",
        "# }\n",
        "#\n",
        "# dependencies = {\n",
        "#     'valid_accuracy': ValidAccuracy\n",
        "# }\n",
        "\n",
        "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
        "def fcd_disk_radius():\n",
        "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
        "# distance between corresponding points in the input tensors.\n",
        "def corresponding_distances(y_true, y_pred):\n",
        "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
        "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
        "    dx = true_pos_x - pred_pos_x\n",
        "    dy = true_pos_y - pred_pos_y\n",
        "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
        "    return distances\n",
        "\n",
        "# 20211231 copied from Find_Concpocuous_Disk\n",
        "def in_disk(y_true, y_pred):\n",
        "    distances = corresponding_distances(y_true, y_pred)\n",
        "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "    # From https://stackoverflow.com/a/42450565/1991373\n",
        "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
        "    # insides = tf.less(distances, relative_disk_radius)\n",
        "    insides = tf.less(distances, fcd_disk_radius())\n",
        "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
        "    return map_to_zero_or_one\n",
        "\n",
        "dependencies = { 'in_disk': in_disk }\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220726 change for Predator class.\n",
        "\n",
        "# model = keras.models.load_model(trained_model, custom_objects=dependencies)\n",
        "\n",
        "def read_default_pre_trained_model():\n",
        "    print('Reading pre-trained model from:', trained_model)\n",
        "    return keras.models.load_model(trained_model, custom_objects=dependencies)\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predator class"
      ],
      "metadata": {
        "id": "RgRdzOk5Vtmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO 20220729 having trouble defining this as a \"class variable\" (c++ static)\n",
        "# so moving it out here for now.\n",
        "\n",
        "# population_of_predators = []\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220724 define for Predator, we want to have a population of them.\n",
        "\n",
        "class Predator:\n",
        "    \"\"\"Represents a Predator in the camouflage simulation. It has a CNN-based\n",
        "       model of visual hunting that identified the position of likely prey.\"\"\"\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "    # untested\n",
        "\n",
        "    population = []\n",
        "\n",
        "    # # Static class function, returns global list of all Predators.\n",
        "    # @ staticmethod\n",
        "    # def get_population():\n",
        "    #     print('in get_population(), size is', len(self.population))\n",
        "    #     return self.population\n",
        "\n",
        "    # # Add or remove a Predator instance from the global population.\n",
        "    # # def add_to_population(self):\n",
        "    # #     population.append(self)\n",
        "    # def remove_from_population(self):\n",
        "    #     population.remove(self)\n",
        "    ############################################################################\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        # Each Predator has its own copy of a prey-finding CNN-based model.\n",
        "        self.model = []\n",
        "        ########################################################################\n",
        "        # TODO 20220729 \n",
        "        # population.append(self)\n",
        "        # self.population.append(self)\n",
        "        # global population_of_predators\n",
        "        # population_of_predators.append(self)\n",
        "        global population_of_predators\n",
        "        self.population.append(self)\n",
        "        ########################################################################\n",
        "\n",
        "    def initialize_to_pre_trained_model(self):\n",
        "        self.model = read_default_pre_trained_model()\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220728 maybe fine_tune_images, fine_tune_labels, etc. should be\n",
        "    # associated with Predator class, but not instance, like c++ class static member.\n",
        "    #\n",
        "    # Arguably, this managing of the dataset for fine tuning ought to be inside\n",
        "    # its own class. But for now it will just be inline class attributes of Predator. \n",
        "\n",
        "    # Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
        "    # https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
        "    # of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
        "    # max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
        "    max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
        "    # List of \"pixel tensors\".\n",
        "    fine_tune_images = []\n",
        "    # List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
        "    fine_tune_labels = []\n",
        "\n",
        "    # Keep track of how often selected prey is nearest center:\n",
        "    nearest_center = 0\n",
        "\n",
        "    ############################################################################\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220728 fine_tune_predator() should become a method of Predator class.\n",
        "    # Maybe it should be called just fine_tune(), Predator.fine_tune()\n",
        "\n",
        "    # Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
        "    # training set. Assume they were \"near misses\" and so training label is actual\n",
        "    # (ground truth) center of disk nearest prediction. Keep a max number of old\n",
        "    # steps to allow gradually forgetting the earliest part of the run.\n",
        "    # def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
        "    def fine_tune_predator(self, pixel_tensor, prediction, step, directory):\n",
        "        # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
        "        xy3 = read_3_centers_from_file(step, directory)\n",
        "        sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
        "\n",
        "        # Accumulate the most recent \"max_training_set_size\" training samples.\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # global fine_tune_images\n",
        "        # global fine_tune_labels\n",
        "        # fine_tune_images.append(pixel_tensor)\n",
        "        # fine_tune_labels.append(sorted_xy3)\n",
        "        self.fine_tune_images.append(pixel_tensor)\n",
        "        self.fine_tune_labels.append(sorted_xy3)\n",
        "        ########################################################################\n",
        "\n",
        "        # If training set has become too large, slice off first element of each.\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # if len(fine_tune_images) > max_training_set_size:\n",
        "        #     fine_tune_images = fine_tune_images[1:]\n",
        "        #     fine_tune_labels = fine_tune_labels[1:]\n",
        "        if len(self.fine_tune_images) > self.max_training_set_size:\n",
        "            self.fine_tune_images = self.fine_tune_images[1:]\n",
        "            self.fine_tune_labels = self.fine_tune_labels[1:]\n",
        "        ########################################################################\n",
        "\n",
        "        # keep track of how often selected prey is nearest center:\n",
        "        temp = xy3.copy()  # needed?\n",
        "        sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
        "        if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
        "            global nearest_center\n",
        "            ####################################################################\n",
        "            # TODO 20220729\n",
        "            # nearest_center += 1\n",
        "            self.nearest_center += 1\n",
        "            ####################################################################\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # print('  nearest_center:',\n",
        "        #       str(int(100 * float(nearest_center) / (step + 1))) + '%',\n",
        "        #       '(nearest_center =', nearest_center, ', steps =', step + 1, ')')\n",
        "        print('  nearest_center:',\n",
        "              str(int(100 * float(self.nearest_center) / (step + 1))) + '%',\n",
        "              '(nearest_center =', self.nearest_center, ', steps =', step + 1, ')')\n",
        "        ########################################################################\n",
        "\n",
        "        # Convert training data list to np arrays\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # images_array = np.array(fine_tune_images)\n",
        "        # labels_array = np.array([x[0] for x in fine_tune_labels])\n",
        "        images_array = np.array(self.fine_tune_images)\n",
        "        labels_array = np.array([x[0] for x in self.fine_tune_labels])\n",
        "        ########################################################################\n",
        "        print('images_array.shape =', images_array.shape)\n",
        "        print('labels_array.shape =', labels_array.shape)\n",
        "\n",
        "    \t# skip fine-tuning until dataset is large enough (10% of max size).\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # if images_array.shape[0] > (max_training_set_size * 0.1):\n",
        "        #     # Do fine-tuning training step using data accumulated during run.\n",
        "        #     history = model.fit(x=images_array, y=labels_array)\n",
        "        #     # Keep log of in_disk metric:\n",
        "        #     write_in_disk_log(step, history)\n",
        "        if images_array.shape[0] > (self.max_training_set_size * 0.1):\n",
        "            # Do fine-tuning training step using data accumulated during run.\n",
        "            history = self.model.fit(x=images_array, y=labels_array)\n",
        "            # Keep log of in_disk metric:\n",
        "            write_in_disk_log(step, history)\n",
        "        ########################################################################\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "\n",
        "\n",
        "# TODO 20220729 prototype storing what had been the global predator model with\n",
        "# one stored in Predator class.\n",
        "\n",
        "test_predator = Predator()\n",
        "test_predator.initialize_to_pre_trained_model()\n",
        "# test_predator.add_to_population()\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4sR8eHOV2pF",
        "outputId": "d9907c69-4c84-4185-83d0-a6c1535bafc8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pre-trained model from: /content/drive/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itBD_Ve0lEYB"
      },
      "source": [
        "# Run test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZQLL52Sk-X9",
        "outputId": "9bbb8a56-9c9f-47a0-aed5-c757e8ba3f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing from communication directory: /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/camo_0.png\n",
            "Removing from communication directory: /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/prey_0.txt\n",
            "Start run in /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "Waiting for camo_0.png and prey_0.txt ... done, elapsed time: 28 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_0.txt\n",
            "  nearest_center: 0% (nearest_center = 0 , steps = 1 )\n",
            "images_array.shape = (1, 128, 128, 3)\n",
            "labels_array.shape = (1, 2)\n",
            "Waiting for camo_1.png and prey_1.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.45549992 0.3471635' to response file find_1.txt\n",
            "  nearest_center: 50% (nearest_center = 1 , steps = 2 )\n",
            "images_array.shape = (2, 128, 128, 3)\n",
            "labels_array.shape = (2, 2)\n",
            "Waiting for camo_2.png and prey_2.txt ..."
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO 20220728 refactoring for Predator class.\n",
        "\n",
        "# Keep track of how often selected prey is nearest center:\n",
        "# nearest_center = 0\n",
        "Predator.nearest_center = 0\n",
        "# Predator.population = []\n",
        "\n",
        "# TODO maybe a reset() method?\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Flush out obsolete files in comms directory.\n",
        "clean_up_communication_directory()\n",
        "\n",
        "# Start fresh run defaulting to step 0.\n",
        "start_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h7-m6IIu6i4"
      },
      "outputs": [],
      "source": [
        "# Normally start from step 0, or if an \"other\" file exists\n",
        "# (eg 'camo_123.jpeg') then restart from that point.\n",
        "\n",
        "# restart_run()"
      ]
    }
  ]
}