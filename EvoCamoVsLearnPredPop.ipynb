{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8AbtMQfMUkt"
   },
   "source": [
    "# Evolutionary Camouflage Versus a Learning Predator Population\n",
    "\n",
    "---\n",
    "\n",
    "**EvoCamoVsLearnPredPop.ipynb**\n",
    "\n",
    "August 23, 2022: this version runs “local mode” with both predator and prey running on the same machine.\n",
    "\n",
    "(The former behavior available with `Rube_Goldberg_mode = True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cr9fUxZxJBRl",
    "outputId": "593bfef6-8130-43c7-8bff-6cba0a4a8ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rube_Goldberg_mode = False\n",
      "shared_directory = /Users/cwr/camo_data/comms/\n",
      "saved_model_directory = /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/\n",
      "TensorFlow version: 2.9.2\n"
     ]
    }
   ],
   "source": [
    "# \"Rube Goldberg\" mode refers to running camouflage evolution on my laptop while\n",
    "# running predator vision in cloud via Colab. State is passed back and forth via\n",
    "# files on Google Drive.\n",
    "\n",
    "# TODO 20220822\n",
    "# Rube_Goldberg_mode = True\n",
    "Rube_Goldberg_mode = False\n",
    "\n",
    "def if_RG_mode(for_RG_mode, for_normal_mode):\n",
    "    return for_RG_mode if Rube_Goldberg_mode else for_normal_mode\n",
    "\n",
    "# PredatorEye directory on Drive.\n",
    "pe_directory = '/content/drive/My Drive/PredatorEye/'\n",
    "\n",
    "# Shared \"communication\" directory on Drive.\n",
    "shared_directory = if_RG_mode(pe_directory + 'evo_camo_vs_static_fcd/',\n",
    "                              '/Users/cwr/camo_data/comms/')\n",
    "\n",
    "# This was meant (20220716) to allow reading original pre-trained model from\n",
    "# Google Drive, but I'll need to retrain it for M1 (Apple Silicon).\n",
    "g_drive_pe_dir = ('/Users/cwr/Library/CloudStorage/' +\n",
    "                  'GoogleDrive-craig.w.reynolds@gmail.com/' +\n",
    "                  'My Drive/PredatorEye/')\n",
    "\n",
    "# Directory for pre-trained Keras/TensorFlow models.\n",
    "saved_model_directory = if_RG_mode(pe_directory, g_drive_pe_dir) + 'saved_models/'\n",
    "\n",
    "\n",
    "print('Rube_Goldberg_mode =', Rube_Goldberg_mode)\n",
    "print('shared_directory =', shared_directory)\n",
    "print('saved_model_directory =', saved_model_directory)\n",
    "\n",
    "# Pathname of pre-trained Keras/TensorFlow model\n",
    "trained_model = saved_model_directory + '20220321_1711_FCD6_rc4'\n",
    "\n",
    "# Directory on Drive for storing fine-tuning dataset.\n",
    "fine_tuning_directory = shared_directory + 'fine_tuning/'\n",
    "\n",
    "my_prefix = \"find_\"\n",
    "other_prefix = \"camo_\"\n",
    "\n",
    "my_suffix =  \".txt\"\n",
    "# other_suffix = \".jpeg\"\n",
    "other_suffix = \".png\"\n",
    "\n",
    "fcd_image_size = 1024\n",
    "fcd_disk_size = 201\n",
    "\n",
    "import time\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "keras_backend.set_image_data_format('channels_last')\n",
    "\n",
    "# Import DiskFind utilities for PredatorEye.\n",
    "import sys\n",
    "if Rube_Goldberg_mode:\n",
    "    sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
    "else:\n",
    "    sys.path.append('/Users/cwr/Documents/code/PredatorEye/')\n",
    "import DiskFind as df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCxVUKpMTEcN"
   },
   "source": [
    "# Ad hoc “predator server”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZF4XLFSBTKOM"
   },
   "outputs": [],
   "source": [
    "# Top level: wait for camo_xxx.jpeg files to appear, respond with find_xxx.txt\n",
    "def start_run(step = 0):\n",
    "    if step == 0:\n",
    "        print('Start run in', shared_directory )\n",
    "    else:\n",
    "        print('Continue run at step', step, ' in', shared_directory)\n",
    "    while True:\n",
    "        perform_step(step, shared_directory)\n",
    "        step += 1\n",
    "\n",
    "# Continue from from the last camo_xxx.jpeg file.\n",
    "def restart_run():\n",
    "    start_run(newest_file_from_other(shared_directory))\n",
    "\n",
    "# Single step: wait for camo file, write response, delete previous response.\n",
    "def perform_step(step, directory):\n",
    "    wait_for_reply(step, shared_directory)\n",
    "    write_response_file(step, shared_directory)\n",
    "    delete_find_file(step - 1, shared_directory)\n",
    "\n",
    "# Read image file for step, apply pre-trained model, write response file.\n",
    "def write_response_file(step, directory):\n",
    "    # Read image file and check for expected format.\n",
    "    image_pathname = make_camo_pathname(step, directory)\n",
    "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
    "    assert df.check_pixel_tensor(pixel_tensor), ('wrong file format: ' +\n",
    "                                                 image_pathname)\n",
    "    # Default Predator's model -- for prototying.\n",
    "    # TODO 20220907 prototype tournament, maybe should be function on Predator class?\n",
    "#     tournament = [Predator.population[0],\n",
    "#                   Predator.population[1],\n",
    "#                   Predator.population[2]]\n",
    "    tournament = Predator.choose_tournament()\n",
    "    model = tournament[0].model\n",
    "    # Run Predator's model on new image.\n",
    "    \n",
    "    tf_pixel_tensor = tf.convert_to_tensor([pixel_tensor])\n",
    "#     prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
    "    prediction = model.predict(tf_pixel_tensor)[0]\n",
    "\n",
    "    \n",
    "#     # Merge this step's image into fine-tuning dataset, and related bookkeeping.\n",
    "#     fine_tuning_dataset.update(pixel_tensor, prediction, step, directory)\n",
    "    \n",
    "    # Second Predator\n",
    "#     sp = tournament[1]\n",
    "#     spm_predict = sp.model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
    "    spm_predict = tournament[1].model.predict(tf_pixel_tensor)[0]\n",
    "    print('  \"other\" prediction:', spm_predict,\n",
    "          ' distance to original prediction:', df.dist2d(spm_predict, prediction))    \n",
    "    # Third Predator\n",
    "#     tp = tournament[2]\n",
    "#     tpm_predict = tp.model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
    "    tpm_predict = tournament[2].model.predict(tf_pixel_tensor)[0]\n",
    "    \n",
    "    # Merge this step's image into fine-tuning dataset, and related bookkeeping.\n",
    "    fine_tuning_dataset.update(pixel_tensor, prediction, step, directory)\n",
    "\n",
    "    \n",
    "    # Sort predictions from the three Predators in a tournament, according to\n",
    "    # ”accuracy” (least aim error).\n",
    "    \n",
    "    predictions_xy3 = [prediction, spm_predict, tpm_predict]\n",
    "    prey_centers_xy3 = read_3_centers_from_file(step, directory)\n",
    "    ranked_predictions_xy3 = rank_tournament(predictions_xy3, prey_centers_xy3)\n",
    "\n",
    "    # Make response string of sorted predictions. (3 positions, an xy3)\n",
    "    response_string = ''\n",
    "    for p in ranked_predictions_xy3:\n",
    "        response_string += str(p[0]) + ' ' + str(p[1]) + ' '\n",
    "\n",
    "    # Write response file.\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(make_find_pathname(step, directory), 'w') as file:\n",
    "        file.write(response_string)\n",
    "    print('Wrote ' + \"'\" + response_string + \"'\",\n",
    "          'to response file', Path(make_find_pathname(step, directory)).name)\n",
    "\n",
    "    # Predator learns from recent experience.\n",
    "    print('  fine-tune default_predator:')\n",
    "    tournament[0].fine_tune_model(pixel_tensor, prediction, step, directory)\n",
    "    \n",
    "#     # For testing/prototyping\n",
    "#     print('  fine-tune second_predator:')\n",
    "#     sp.fine_tune_model(pixel_tensor, prediction, step, directory)\n",
    "#     print('  fine-tune third_predator:')\n",
    "#     tp.fine_tune_model(pixel_tensor, prediction, step, directory)\n",
    "    # For testing/prototyping\n",
    "    print('  fine-tune second_predator:')\n",
    "    tournament[1].fine_tune_model(pixel_tensor, prediction, step, directory)\n",
    "    print('  fine-tune third_predator:')\n",
    "    tournament[2].fine_tune_model(pixel_tensor, prediction, step, directory)\n",
    "\n",
    "\n",
    "# Delete the given file, presumably after having written the next one.\n",
    "def delete_find_file(step, directory):\n",
    "    # Why doesn't pathlib provide a Path.remove() method like os?\n",
    "    # TODO oh, missing_ok was added at pathlib version 3.8.\n",
    "    # Path(makeMyPathname(step, directory)).unlink(missing_ok=True)\n",
    "    p = Path(make_find_pathname(step, directory))\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "\n",
    "# Delete any remaining file in commuications directory to start a new run.\n",
    "def clean_up_communication_directory():\n",
    "    def delete_directory_contents(directory_path):\n",
    "        for path in directory_path.iterdir():\n",
    "            print('Removing from communication directory:', path)\n",
    "            if path.is_dir():\n",
    "                delete_directory_contents(path)\n",
    "                path.rmdir()\n",
    "            else:\n",
    "                path.unlink()\n",
    "    delete_directory_contents(Path(shared_directory))\n",
    "\n",
    "# From pathname for file of given step number from the \"other\" agent.\n",
    "def make_camo_pathname(step, directory):\n",
    "    return directory + other_prefix + str(step) + other_suffix\n",
    "\n",
    "# Form pathname for \"find_xx.txt\" response file from \"this\" agent.\n",
    "def make_find_pathname(step, directory):\n",
    "    return directory + my_prefix + str(step) + my_suffix\n",
    "\n",
    "# Form pathname for \"prey_xx.txt\" ground truth file from \"other\" agent.\n",
    "def make_prey_pathname(step, directory):\n",
    "    return directory + 'prey_' + str(step) + '.txt'\n",
    "\n",
    "# Used to ping the comms directory when it seems hung.\n",
    "def write_ping_file(count, step, directory):\n",
    "    pn = directory + 'ping_cloud_' + str(step) + '.txt'\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(pn, 'w') as file:\n",
    "        file.write(str(count))\n",
    "    print('Ping comms: ', count, pn)\n",
    "\n",
    "# Wait until other agent's file for given step appears.\n",
    "def wait_for_reply(step, directory):\n",
    "    camo_pathname = Path(make_camo_pathname(step, directory))\n",
    "    camo_filename = camo_pathname.name\n",
    "    prey_pathname = Path(make_prey_pathname(step, directory))\n",
    "    prey_filename = prey_pathname.name\n",
    "    print('Waiting for', camo_filename, 'and', prey_filename, '...',\n",
    "          end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    # Loop until both files are present, waiting 1 second between tests.\n",
    "    test_count = 0\n",
    "    while not (is_file_present(camo_pathname) and\n",
    "               is_file_present(prey_pathname)):\n",
    "        time.sleep(1)\n",
    "        test_count += 1\n",
    "        if (test_count % 100) == 0:\n",
    "            write_ping_file(test_count, step, directory)\n",
    "    print(' done, elapsed time:', int(time.time() - start_time), 'seconds.')\n",
    "\n",
    "# Like fs::exists()\n",
    "def is_file_present(file):\n",
    "    result = False\n",
    "    verify_comms_directory_reachable()\n",
    "    filename = Path(file).name\n",
    "    directory = Path(file).parent\n",
    "    for i in directory.iterdir():\n",
    "        if i.name == filename:\n",
    "            result = True\n",
    "    return result\n",
    "\n",
    "# Returns the step number of the newest file from \"other\" in given directory.\n",
    "# (So if \"camo_573.jpeg\" is the only \"other\" file there, returns int 573)\n",
    "def newest_file_from_other(directory):\n",
    "    steps = [0]  # Default to zero in case dir is empty.\n",
    "    for filename in Path(directory).iterdir():\n",
    "        name = filename.name\n",
    "        if other_prefix == name[0:len(other_prefix)]:\n",
    "            steps.append(int(name.split(\".\")[0].split(\"_\")[1]))\n",
    "    return max(steps)\n",
    "\n",
    "# Read ground truth prey center location data provided in \"prey_n.txt\" file.\n",
    "def read_3_centers_from_file(step, directory):\n",
    "    # Read contents of file as string.\n",
    "    verify_comms_directory_reachable()\n",
    "    with open(make_prey_pathname(step, directory), 'r') as file:\n",
    "        prey_centers_string = file.read()\n",
    "    # Split string at whitespace, map to 6 floats, reshape into 3 xy pairs.\n",
    "    # (TODO could probably be rewritten cleaner with \"list comprehension\")\n",
    "    array = np.reshape(list(map(float, prey_centers_string.split())), (3, 2))\n",
    "    return array.tolist()\n",
    "\n",
    "# Keep log of in_disk metric.\n",
    "def write_in_disk_log(step, history):\n",
    "    if step % 10 == 0:\n",
    "        in_disk = history.history[\"in_disk\"][0]\n",
    "        pathname = shared_directory + 'in_disk_log.csv'\n",
    "        verify_comms_directory_reachable()\n",
    "        with open(pathname, 'a') as file:\n",
    "            if step == 0:\n",
    "                file.write('step,in_disk\\n')\n",
    "            file.write(str(step) + ',' + \"{:.4f}\".format(in_disk) + '\\n')\n",
    "\n",
    "# Just wait in retry loop if shared \"comms\" directory become unreachable.\n",
    "# Probably will return shortly, better to wait than signal a file error.\n",
    "# (This is called from places with a local \"directory\" but it uses global value.)\n",
    "def verify_comms_directory_reachable():\n",
    "    seconds = 0\n",
    "    # shared_directory_pathname = Path(shared_directory)\n",
    "    # while not shared_directory_pathname.is_dir():\n",
    "    while not Path(shared_directory).is_dir():\n",
    "        print(\"Shared “comms” directory,\", shared_directory, \n",
    "              \"has been inaccessible for\", seconds, \"seconds.\")\n",
    "        time.sleep(1)  # wait 1 sec\n",
    "        seconds += 1\n",
    "\n",
    "# Given 3 prey positions (\"xy3\"), sort them by proximity to \"point\" (prediction)\n",
    "def sort_xy3_by_proximity_to_point(xy3, point):\n",
    "    # print('xy3 =', xy3)\n",
    "    xy3_plus_distance = [[df.dist2d(xy, point), xy] for xy in xy3]\n",
    "    # print('xy3_plus_distance =', xy3_plus_distance)\n",
    "    sorted_xy3_plus_key = sorted(xy3_plus_distance, key=lambda x: x[0])\n",
    "    # print('sorted_xy3_plus_key =', sorted_xy3_plus_key)\n",
    "    sorted_xy3 = [x[1] for x in sorted_xy3_plus_key]\n",
    "    # print('sorted_xy3 =', sorted_xy3)\n",
    "    return sorted_xy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDtbk88sVGxk"
   },
   "source": [
    "# Read pre-trained model\n",
    "\n",
    "As I integrate this into the Predator class, this is no longer “Read pre-trained model” but more like “Some utilities for reading the pre-trained model”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iLVIRi_vU9gN"
   },
   "outputs": [],
   "source": [
    "# Read pre-trained TensorFlow \"predator vision\" model.\n",
    "\n",
    "# print('Reading pre-trained model from:', trained_model)\n",
    "\n",
    "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
    "#\n",
    "# dependencies = {\n",
    "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
    "#     'attention': attention(return_sequences=True)\n",
    "# }\n",
    "#\n",
    "# dependencies = {\n",
    "#     'valid_accuracy': ValidAccuracy\n",
    "# }\n",
    "\n",
    "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
    "def fcd_disk_radius():\n",
    "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
    "\n",
    "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
    "# distance between corresponding points in the input tensors.\n",
    "def corresponding_distances(y_true, y_pred):\n",
    "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
    "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
    "    dx = true_pos_x - pred_pos_x\n",
    "    dy = true_pos_y - pred_pos_y\n",
    "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
    "    return distances\n",
    "\n",
    "# 20211231 copied from Find_Concpocuous_Disk\n",
    "def in_disk(y_true, y_pred):\n",
    "    distances = corresponding_distances(y_true, y_pred)\n",
    "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
    "\n",
    "    # From https://stackoverflow.com/a/42450565/1991373\n",
    "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
    "    # insides = tf.less(distances, relative_disk_radius)\n",
    "    insides = tf.less(distances, fcd_disk_radius())\n",
    "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
    "    return map_to_zero_or_one\n",
    "\n",
    "dependencies = { 'in_disk': in_disk }\n",
    "\n",
    "def read_default_pre_trained_model():\n",
    "    print('Reading pre-trained model from:', trained_model)\n",
    "    return keras.models.load_model(trained_model, custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlnzeJgbj6bS"
   },
   "source": [
    "# FineTuningDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8Btaj5aXj8iw"
   },
   "outputs": [],
   "source": [
    "class FineTuningDataset:\n",
    "    \"\"\"Manages the dataset of images and labels for fine-tuning.\"\"\"\n",
    "\n",
    "    # Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
    "    # https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
    "    # of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
    "    # max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
    "    max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
    "    # List of \"pixel tensors\".\n",
    "    fine_tune_images = []\n",
    "    # List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
    "    fine_tune_labels = []\n",
    "\n",
    "    def update(self, pixel_tensor, prediction, step, directory):\n",
    "        # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
    "        xy3 = read_3_centers_from_file(step, directory)\n",
    "        sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
    "\n",
    "        # Accumulate the most recent \"max_training_set_size\" training samples.\n",
    "        self.fine_tune_images.append(pixel_tensor)\n",
    "        self.fine_tune_labels.append(sorted_xy3)\n",
    "\n",
    "        # If training set has become too large, slice off first element of each.\n",
    "        if len(self.fine_tune_images) > self.max_training_set_size:\n",
    "            self.fine_tune_images = self.fine_tune_images[1:]\n",
    "            self.fine_tune_labels = self.fine_tune_labels[1:]\n",
    "\n",
    "        print('  fine_tune_images shape =', np.shape(self.fine_tune_images),\n",
    "              '-- fine_tune_labels shape =', np.shape(self.fine_tune_labels))\n",
    "        \n",
    "\n",
    "# Create a global FineTuningDataset object.\n",
    "# (TODO globals are usually a bad idea, reconsider this.)\n",
    "fine_tuning_dataset = FineTuningDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgRdzOk5Vtmr"
   },
   "source": [
    "# Predator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4sR8eHOV2pF",
    "outputId": "293b0fdd-0888-4840-de81-b779a4cfb754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pre-trained model from: /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n",
      "Reading pre-trained model from: /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n",
      "Reading pre-trained model from: /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n",
      "Reading pre-trained model from: /Users/cwr/Library/CloudStorage/GoogleDrive-craig.w.reynolds@gmail.com/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n",
      "Created population of 3 Predators.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class Predator:\n",
    "    \"\"\"Represents a Predator in the camouflage simulation. It has a CNN-based\n",
    "       model of visual hunting that identified the position of likely prey.\"\"\"\n",
    "\n",
    "    # Global list of active Predators. (As a class variable.)\n",
    "    population = []\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO 20220905 cache default_pre_trained_model\n",
    "    default_pre_trained_model = read_default_pre_trained_model()\n",
    "    ############################################################################\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        # Each Predator has its own copy of a prey-finding CNN-based model.\n",
    "        self.model = []\n",
    "        # By default add this new Predator to the population (TODO reconsider)\n",
    "        Predator.population.append(self)\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO 20220905 cache default_pre_trained_model\n",
    "    \n",
    "#     # Set this Predator's model to default.\n",
    "#     def initialize_to_pre_trained_model(self):\n",
    "#         self.model = read_default_pre_trained_model()\n",
    "\n",
    "#     # Set this Predator's model to default.\n",
    "#     def initialize_to_pre_trained_model(self):\n",
    "#         self.model = self.default_pre_trained_model\n",
    "\n",
    "    # TODO 20220905 changed back because was just copying pointer not deep copy.\n",
    "    def initialize_to_pre_trained_model(self):\n",
    "        self.model = read_default_pre_trained_model()\n",
    "    ############################################################################\n",
    "\n",
    "    # Keep track of how often selected prey is nearest center:\n",
    "    nearest_center = 0\n",
    "\n",
    "    # Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
    "    # training set. Assume they were \"near misses\" and so training label is actual\n",
    "    # (ground truth) center of disk nearest prediction. Keep a max number of old\n",
    "    # steps to allow gradually forgetting the earliest part of the run.\n",
    "    def fine_tune_model(self, pixel_tensor, prediction, step, directory):\n",
    "        # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
    "        xy3 = read_3_centers_from_file(step, directory)\n",
    "        sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
    "\n",
    "        # keep track of how often selected prey is nearest center:\n",
    "        temp = xy3.copy()  # needed?\n",
    "        sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
    "        if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
    "            Predator.nearest_center += 1\n",
    "        \n",
    "        # TODO 20220829 \"ad-hoc-ly\" adjust for two models running, hence NC count doubled.\n",
    "        # print('  nearest_center:',\n",
    "        #       str(int(100 * float(self.nearest_center) / (step + 1))) + '%',\n",
    "        #       '(nearest_center =', self.nearest_center, ', steps =', step + 1, ')')\n",
    "        nc = self.nearest_center / 2\n",
    "        print('  nearest_center:',\n",
    "              str(int(100 * float(nc) / (step + 1))) + '%',\n",
    "              '(nearest_center =', nc, ', steps =', step + 1, ')')\n",
    "\n",
    "        # Convert training data list to np arrays\n",
    "        images_array = np.array(fine_tuning_dataset.fine_tune_images)\n",
    "        labels_array = np.array([x[0] for x in fine_tuning_dataset.fine_tune_labels])\n",
    "\n",
    "        # print('images_array.shape =', images_array.shape,\n",
    "        #       '-- labels_array.shape =', labels_array.shape)\n",
    "\n",
    "    \t# Skip fine-tuning until dataset is large enough (10% of max size).\n",
    "        ########################################################################\n",
    "        # TODO 20220803 clone model\n",
    "\n",
    "        # print('disabled \"Skip fine-tuning until dataset is large enough\"')\n",
    "        # # if images_array.shape[0] > (fine_tuning_dataset.max_training_set_size * 0.1):\n",
    "        # if images_array.shape[0] > 0: ##########################################\n",
    "        #     # Do fine-tuning training step using data accumulated during run.\n",
    "        #     history = self.model.fit(x=images_array, y=labels_array)\n",
    "        #     # Keep log of in_disk metric:\n",
    "        #     write_in_disk_log(step, history)\n",
    "\n",
    "        # print('disabled \"Skip fine-tuning until dataset is large enough\"')\n",
    "        # # if images_array.shape[0] > (fine_tuning_dataset.max_training_set_size * 0.1):\n",
    "        # if images_array.shape[0] > 0: ##########################################\n",
    "        #     # Do fine-tuning training step using data accumulated during run.\n",
    "        #     history = self.model.fit(x=images_array, y=labels_array)\n",
    "        #     # Keep log of in_disk metric:\n",
    "        #     write_in_disk_log(step, history)\n",
    "\n",
    "        # TODO 20220823 restore \"Skip fine-tuning until dataset is large enough\"\n",
    "        \n",
    "#         print('disabled \"Skip fine-tuning until dataset is large enough\"')\n",
    "#         if images_array.shape[0] > 0: ##########################################\n",
    "\n",
    "        if images_array.shape[0] > (fine_tuning_dataset.max_training_set_size * 0.1):\n",
    "\n",
    "            # # Do fine-tuning training step using data accumulated during run.\n",
    "            # history = self.model.fit(x=images_array, y=labels_array)\n",
    "            \n",
    "            # TODO 20220823 -- run fine-tuning on CPU only.\n",
    "            print('Running on CPU ONLY!')\n",
    "            with tf.device('/cpu:0'):\n",
    "                # Do fine-tuning training step using data accumulated during run.\n",
    "                history = self.model.fit(x=images_array, y=labels_array)\n",
    "            \n",
    "            # Keep log of in_disk metric:\n",
    "            write_in_disk_log(step, history)\n",
    "\n",
    "        print(end='  ')\n",
    "        self.print_model_trace()\n",
    "        ########################################################################\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO 20220803 clone model\n",
    "\n",
    "    # # Copy the neural net model of a given predator into this one.\n",
    "    # def copy_model(self, another_predator):\n",
    "    #     # No this is wrong, just does a shallow copy\n",
    "    #     # self.model = another_predator.model\n",
    "    #     self.model = tf.keras.models.clone_model(another_predator.model)\n",
    "    #     # Compile newly cloned model.\n",
    "    #     # compile_disk_finder_model(self.model)\n",
    "    #     df.compile_disk_finder_model(self.model)\n",
    "\n",
    "    # Copy the neural net model of a given predator into this one. (From \"Make\n",
    "    # deep copy of keras model\" https://stackoverflow.com/a/54368176/1991373)\n",
    "    def copy_model(self, another_predator):\n",
    "        other_model = another_predator.model\n",
    "        # Clone layer structure of other model.\n",
    "        # self.model = tf.keras.models.clone_model(another_predator.model)\n",
    "        self.model = tf.keras.models.clone_model(other_model)\n",
    "        # Compile newly cloned model.\n",
    "        df.compile_disk_finder_model(self.model)\n",
    "\n",
    "        # Copy weights of other model.\n",
    "        self.model.set_weights(other_model.get_weights())\n",
    "\n",
    "    ############################################################################\n",
    "\n",
    "    # Modify this Predator's model by adding noise to its weights.\n",
    "    def jiggle_model(self):\n",
    "        weight_perturbation(self.model, 0.001)\n",
    "    \n",
    "    # Print the \"first\" weight of each layer of this Predator's Keras model.\n",
    "    def print_model_trace(self):\n",
    "        for layer in self.model.layers:\n",
    "            trainable_weights = layer.trainable_variables\n",
    "            for weight in trainable_weights:            \n",
    "                weight_shape = tf.shape(weight)\n",
    "                total_size = tf.math.reduce_prod(weight_shape)\n",
    "                reshape_1d = tf.reshape(weight, [total_size])\n",
    "                \n",
    "                # TODO 20220829 take \"middle\" not first parameter.\n",
    "                # value = reshape_1d[0].numpy()\n",
    "                middle = math.floor(total_size / 2)\n",
    "                value = reshape_1d[middle].numpy()\n",
    "        \n",
    "                print(round(value, 2), end = \" \")\n",
    "        print()\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO 20220905\n",
    "    # Create the given number of Predator objects\n",
    "    # (TODO maybe the pretrained model should be an arg?)\n",
    "    def initialize_predator_population(population_size):\n",
    "        for i in range(population_size):\n",
    "            p = Predator()\n",
    "            p.initialize_to_pre_trained_model()\n",
    "            p.jiggle_model()\n",
    "        print('Created population of', population_size, 'Predators.')\n",
    "    ############################################################################\n",
    "    \n",
    "    #     tournament = [Predator.population[0],\n",
    "    #                   Predator.population[1],\n",
    "    #                   Predator.population[2]]\n",
    "#         tournament = Predator.choose_tournament()\n",
    "        \n",
    "    # TODO 20220907 prototype tournament maker, eventually random, now just first 3\n",
    "    def choose_tournament(size = 3):\n",
    "        tournament = []\n",
    "        for i in range(size):\n",
    "            tournament.append(Predator.population[i])\n",
    "        return tournament\n",
    "\n",
    "# Utility based on https://stackoverflow.com/a/64542651/1991373\n",
    "def weight_perturbation(model, max_range):\n",
    "    \"\"\"Add noise to all weights in a Keras model.\"\"\"\n",
    "    for layer in model.layers:\n",
    "        trainable_weights = layer.trainable_variables\n",
    "        for weight in trainable_weights:\n",
    "            random_weights = tf.random.uniform(tf.shape(weight),\n",
    "                                               max_range / -2,\n",
    "                                               max_range / 2,\n",
    "                                               dtype=tf.float32)\n",
    "            weight.assign_add(random_weights)\n",
    "\n",
    "############################################################################\n",
    "# TODO 20220803 clone model\n",
    "#     This should be a utility in DiskFind.py,\n",
    "#     and be called from make_disk_finder_model()\n",
    "\n",
    "# # Compile a disk finder model.\n",
    "# def compile_disk_finder_model(model):\n",
    "#     # Compile with mse loss, tracking accuracy and fraction-inside-disk.\n",
    "#     model.compile(loss='mse', optimizer='adam', metrics=[\"accuracy\", df.in_disk])\n",
    "\n",
    "# # Compile a disk finder model.\n",
    "# def compile_disk_finder_model(model):\n",
    "#     # Compile with mse loss, tracking accuracy and fraction-inside-disk.\n",
    "#     model.compile(loss='mse', optimizer='adam', metrics=[\"accuracy\", in_disk])\n",
    "\n",
    "############################################################################\n",
    "\n",
    "# TODO 20220905 -- this should probably not be at global scope:\n",
    "# Create population of 12 Predators.\n",
    "# Predator.initialize_predator_population(12)\n",
    "Predator.initialize_predator_population(3)\n",
    "print(len(Predator.population))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype rank tournament of Predators by min prediction-prey distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order a tournamant of 3 Predators by sorting their three xy predictions. They\n",
    "# are ordered by distance from prediction to the nearest of three prey centers\n",
    "# (smaller being earlier in sort order -- think of it as \"aiming error\").\n",
    "\n",
    "def rank_tournament(predictions_xy3, prey_centers_xy3):\n",
    "    return sort_xy3_by_least_aim_error(predictions_xy3, prey_centers_xy3)\n",
    "\n",
    "# Given 3 predator prediction positions (\"xy3\"), sort them by \"least aim error\",\n",
    "# that is, the distance from the prediction to the nearest prey position, so\n",
    "# smallest errors sort to the front of the collection.\n",
    "\n",
    "def sort_xy3_by_least_aim_error(predictions_xy3, prey_centers_xy3):\n",
    "    predictions_with_key = [[aim_error(xy, prey_centers_xy3), xy]\n",
    "                            for xy in predictions_xy3]\n",
    "    # print('predictions_with_key =', predictions_with_key)\n",
    "    sorted_predictions_with_key = sorted(predictions_with_key,\n",
    "                                         key=lambda x: x[0])\n",
    "    # print('sorted_predictions_with_key =', sorted_predictions_with_key)\n",
    "    sorted_predictions = [x[1] for x in sorted_predictions_with_key]\n",
    "    # print('sorted_predictions =', sorted_predictions)\n",
    "    return sorted_predictions\n",
    "\n",
    "# Given one predator's xy prediction, and three prey center positions, find the\n",
    "# \"aim error\": the distance from the predition to the nearest prey center.\n",
    "def aim_error(prediction_xy, prey_centers_xy3):\n",
    "    min_aim_error = math.inf\n",
    "    for xy in prey_centers_xy3:\n",
    "        distance = df.dist2d(xy, prediction_xy)\n",
    "        if min_aim_error > distance:\n",
    "            min_aim_error = distance\n",
    "    return min_aim_error\n",
    "\n",
    "\n",
    "# rank_tournament([[0.2, 0.5], [0.4, 0.5], [0.3, 0.5]],\n",
    "#                 [[0.5, 0.5], [0.6, 0.5], [0.7, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itBD_Ve0lEYB"
   },
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZQLL52Sk-X9",
    "outputId": "d8cd0a60-3fc8-484e-d32b-2c9ae0b157d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing from communication directory: /Users/cwr/camo_data/comms/ping_cloud_6.txt\n",
      "Removing from communication directory: /Users/cwr/camo_data/comms/find_5.txt\n",
      "Removing from communication directory: /Users/cwr/camo_data/comms/prey_4.txt\n",
      "Removing from communication directory: /Users/cwr/camo_data/comms/prey_5.txt\n",
      "Removing from communication directory: /Users/cwr/camo_data/comms/camo_5.png\n",
      "Start run in /Users/cwr/camo_data/comms/\n",
      "Waiting for camo_0.png and prey_0.txt ... done, elapsed time: 12 seconds.\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "  \"other\" prediction: [0.30062202 0.411969  ]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "  fine_tune_images shape = (1, 128, 128, 3) -- fine_tune_labels shape = (1, 3, 2)\n",
      "Wrote '0.30062202 0.411969 0.30062202 0.411969 0.30062202 0.411969 ' to response file find_0.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 50% (nearest_center = 0.5 , steps = 1 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 100% (nearest_center = 1.0 , steps = 1 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 150% (nearest_center = 1.5 , steps = 1 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_1.png and prey_1.txt ... done, elapsed time: 2 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  \"other\" prediction: [0.78462493 0.55190736]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  fine_tune_images shape = (2, 128, 128, 3) -- fine_tune_labels shape = (2, 3, 2)\n",
      "Wrote '0.78462493 0.55190736 0.78462493 0.55190736 0.78462493 0.55190736 ' to response file find_1.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 75% (nearest_center = 1.5 , steps = 2 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 75% (nearest_center = 1.5 , steps = 2 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 75% (nearest_center = 1.5 , steps = 2 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_2.png and prey_2.txt ... done, elapsed time: 1 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "  \"other\" prediction: [0.5329889 0.5749443]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  fine_tune_images shape = (3, 128, 128, 3) -- fine_tune_labels shape = (3, 3, 2)\n",
      "Wrote '0.5329889 0.5749443 0.5329889 0.5749443 0.5329889 0.5749443 ' to response file find_2.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 50% (nearest_center = 1.5 , steps = 3 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 50% (nearest_center = 1.5 , steps = 3 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 50% (nearest_center = 1.5 , steps = 3 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_3.png and prey_3.txt ... done, elapsed time: 2 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.5605529  0.73394185]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  fine_tune_images shape = (4, 128, 128, 3) -- fine_tune_labels shape = (4, 3, 2)\n",
      "Wrote '0.5605529 0.73394185 0.5605529 0.73394185 0.5605529 0.73394185 ' to response file find_3.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 50% (nearest_center = 2.0 , steps = 4 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 62% (nearest_center = 2.5 , steps = 4 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 75% (nearest_center = 3.0 , steps = 4 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_4.png and prey_4.txt ... done, elapsed time: 4 seconds.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.5329889 0.5749443]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  fine_tune_images shape = (5, 128, 128, 3) -- fine_tune_labels shape = (5, 3, 2)\n",
      "Wrote '0.5329889 0.5749443 0.5329889 0.5749443 0.5329889 0.5749443 ' to response file find_4.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 60% (nearest_center = 3.0 , steps = 5 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 60% (nearest_center = 3.0 , steps = 5 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 60% (nearest_center = 3.0 , steps = 5 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_5.png and prey_5.txt ... done, elapsed time: 1 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.30499122 0.41235626]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  fine_tune_images shape = (6, 128, 128, 3) -- fine_tune_labels shape = (6, 3, 2)\n",
      "Wrote '0.30499122 0.41235626 0.30499122 0.41235626 0.30499122 0.41235626 ' to response file find_5.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 50% (nearest_center = 3.0 , steps = 6 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 50% (nearest_center = 3.0 , steps = 6 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 50% (nearest_center = 3.0 , steps = 6 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_6.png and prey_6.txt ... done, elapsed time: 2 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.5329889 0.5749443]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  fine_tune_images shape = (7, 128, 128, 3) -- fine_tune_labels shape = (7, 3, 2)\n",
      "Wrote '0.5329889 0.5749443 0.5329889 0.5749443 0.5329889 0.5749443 ' to response file find_6.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 50% (nearest_center = 3.5 , steps = 7 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 57% (nearest_center = 4.0 , steps = 7 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 64% (nearest_center = 4.5 , steps = 7 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_7.png and prey_7.txt ... done, elapsed time: 1 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "  \"other\" prediction: [0.55741256 0.61511874]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  fine_tune_images shape = (8, 128, 128, 3) -- fine_tune_labels shape = (8, 3, 2)\n",
      "Wrote '0.55741256 0.61511874 0.55741256 0.61511874 0.55741256 0.61511874 ' to response file find_7.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 62% (nearest_center = 5.0 , steps = 8 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 68% (nearest_center = 5.5 , steps = 8 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 75% (nearest_center = 6.0 , steps = 8 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for camo_8.png and prey_8.txt ... done, elapsed time: 1 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "  \"other\" prediction: [0.7597724  0.60736597]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  fine_tune_images shape = (9, 128, 128, 3) -- fine_tune_labels shape = (9, 3, 2)\n",
      "Wrote '0.7597724 0.60736597 0.7597724 0.60736597 0.7597724 0.60736597 ' to response file find_8.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 66% (nearest_center = 6.0 , steps = 9 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 66% (nearest_center = 6.0 , steps = 9 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 66% (nearest_center = 6.0 , steps = 9 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_9.png and prey_9.txt ... done, elapsed time: 1 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.5329889 0.5749443]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "  fine_tune_images shape = (10, 128, 128, 3) -- fine_tune_labels shape = (10, 3, 2)\n",
      "Wrote '0.5329889 0.5749443 0.5329889 0.5749443 0.5329889 0.5749443 ' to response file find_9.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 60% (nearest_center = 6.0 , steps = 10 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 60% (nearest_center = 6.0 , steps = 10 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 60% (nearest_center = 6.0 , steps = 10 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_10.png and prey_10.txt ... done, elapsed time: 4 seconds.\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  \"other\" prediction: [0.7901479  0.21819559]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "  fine_tune_images shape = (11, 128, 128, 3) -- fine_tune_labels shape = (11, 3, 2)\n",
      "Wrote '0.7901479 0.21819559 0.7901479 0.21819559 0.7901479 0.21819559 ' to response file find_10.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 54% (nearest_center = 6.0 , steps = 11 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 54% (nearest_center = 6.0 , steps = 11 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 54% (nearest_center = 6.0 , steps = 11 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_11.png and prey_11.txt ... done, elapsed time: 2 seconds.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.5329889 0.5749443]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  fine_tune_images shape = (12, 128, 128, 3) -- fine_tune_labels shape = (12, 3, 2)\n",
      "Wrote '0.5329889 0.5749443 0.5329889 0.5749443 0.5329889 0.5749443 ' to response file find_11.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 54% (nearest_center = 6.5 , steps = 12 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 58% (nearest_center = 7.0 , steps = 12 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 62% (nearest_center = 7.5 , steps = 12 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_12.png and prey_12.txt ... done, elapsed time: 2 seconds.\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  \"other\" prediction: [0.7424136  0.82287294]  distance to original prediction: 0.0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "  fine_tune_images shape = (13, 128, 128, 3) -- fine_tune_labels shape = (13, 3, 2)\n",
      "Wrote '0.7424136 0.82287294 0.7424136 0.82287294 0.7424136 0.82287294 ' to response file find_12.txt\n",
      "  fine-tune default_predator:\n",
      "  nearest_center: 57% (nearest_center = 7.5 , steps = 13 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune second_predator:\n",
      "  nearest_center: 57% (nearest_center = 7.5 , steps = 13 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "  fine-tune third_predator:\n",
      "  nearest_center: 57% (nearest_center = 7.5 , steps = 13 )\n",
      "  -0.39 -0.01 -0.11 -0.97 -0.19 -0.1 0.1 0.01 -0.01 -3.86 0.29 1.05 -0.16 -5.44 -0.02 6.25 0.03 0.21 \n",
      "Waiting for camo_13.png and prey_13.txt ...Ping comms:  100 /Users/cwr/camo_data/comms/ping_cloud_13.txt\n"
     ]
    }
   ],
   "source": [
    "# # TODO 20220827 testing print_model_trace\n",
    "# test_predator.print_model_trace()\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of how often selected prey is nearest center:\n",
    "Predator.nearest_center = 0\n",
    "\n",
    "# Predator.population = []\n",
    "# TODO maybe a Predator.reset() method?\n",
    "\n",
    "# Flush out obsolete files in comms directory.\n",
    "clean_up_communication_directory()\n",
    "\n",
    "# Start fresh run defaulting to step 0.\n",
    "start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h7-m6IIu6i4"
   },
   "outputs": [],
   "source": [
    "# Normally start from step 0, or if an \"other\" file exists\n",
    "# (eg 'camo_123.jpeg') then restart from that point.\n",
    "\n",
    "# restart_run()\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "EvoCamoVsLearnPredPop.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
