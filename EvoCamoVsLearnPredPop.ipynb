{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvoCamoVsLearnPredPop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8AbtMQfMUkt"
      },
      "source": [
        "# Evolutionary Camouflage Versus a Learning Predator Population\n",
        "\n",
        "---\n",
        "\n",
        "EvoCamoVsLearnPredPop.ipynb\n",
        "\n",
        "Started as a copy of EvoCamoVsLearningPredator.ipynb as of 20220607\n",
        "\n",
        "On 20220716 starting from here to prototype “local” version running on my Apple Silicon M1 laptop. Got as far as trying to read pre-tained “FCD6_rc4” model but it complained it was compiled for Intel, while this is Apple Silicon.\n",
        "\n",
        "OK now on 20220722 I am converting this back to \"Rube Goldberg\" mode where predator vision happens in the cloud, and camouflage evolution runs on my laptop. I tried using the [TensorFlow-Metal plugin](https://developer.apple.com/metal/tensorflow-plugin/), but ran into a [bug](https://developer.apple.com/forums/thread/706920). Until that is fixed I will fall back to the old half-cloud-half-laptop approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cr9fUxZxJBRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b61d40-ced6-4777-f65b-976698a94581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rube_Goldberg_mode = True\n",
            "shared_directory = /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "saved_model_directory = /content/drive/My Drive/PredatorEye/saved_models/\n",
            "TensorFlow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "# \"Rube Goldberg\" mode refers to running camouflage evolution on my laptop while\n",
        "# running predator vision in cloud via Colab. State is passed back and forth via\n",
        "# files on Google Drive.\n",
        "Rube_Goldberg_mode = True\n",
        "def if_RG_mode(for_RG_mode, for_normal_mode):\n",
        "    return for_RG_mode if Rube_Goldberg_mode else for_normal_mode\n",
        "\n",
        "# PredatorEye directory on Drive.\n",
        "pe_directory = '/content/drive/My Drive/PredatorEye/'\n",
        "\n",
        "# Shared \"communication\" directory on Drive.\n",
        "shared_directory = if_RG_mode(pe_directory + 'evo_camo_vs_static_fcd/',\n",
        "                              '/Users/cwr/comms/')\n",
        "\n",
        "# This was meant (20220716) to allow reading original pre-trained model from\n",
        "# Google Drive, but I'll need to retrain it for M1 (Apple Silicon).\n",
        "g_drive_pe_dir = ('/Users/cwr/Library/CloudStorage/' +\n",
        "                  'GoogleDrive-craig.w.reynolds@gmail.com/' +\n",
        "                  'My Drive/PredatorEye/')\n",
        "\n",
        "# Directory for pre-trained Keras/TensorFlow models.\n",
        "saved_model_directory = if_RG_mode(pe_directory, g_drive_pe_dir) + 'saved_models/'\n",
        "\n",
        "\n",
        "print('Rube_Goldberg_mode =', Rube_Goldberg_mode)\n",
        "print('shared_directory =', shared_directory)\n",
        "print('saved_model_directory =', saved_model_directory)\n",
        "\n",
        "# Pathname of pre-trained Keras/TensorFlow model\n",
        "# trained_model = saved_model_directory + '20220202_1211_Find_3_Disks_complex'\n",
        "# trained_model = saved_model_directory + '20220222_1747_F3D_augmented_rc4'\n",
        "# trained_model = saved_model_directory + '20220227_0746_F3D2_a'\n",
        "# trained_model = saved_model_directory + '20220304_1135_FCD5_a'\n",
        "trained_model = saved_model_directory + '20220321_1711_FCD6_rc4'\n",
        "# model = []\n",
        "\n",
        "# Directory on Drive for storing fine-tuning dataset.\n",
        "fine_tuning_directory = shared_directory + 'fine_tuning/'\n",
        "\n",
        "my_prefix = \"find_\"\n",
        "other_prefix = \"camo_\"\n",
        "\n",
        "my_suffix =  \".txt\"\n",
        "# other_suffix = \".jpeg\"\n",
        "other_suffix = \".png\"\n",
        "\n",
        "fcd_image_size = 1024\n",
        "fcd_disk_size = 201\n",
        "\n",
        "import time\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "from tensorflow.keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')\n",
        "\n",
        "# Import DiskFind utilities for PredatorEye.\n",
        "import sys\n",
        "if Rube_Goldberg_mode:\n",
        "    sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
        "else:\n",
        "    sys.path.append('/Users/cwr/Documents/code/PredatorEye/')\n",
        "import DiskFind as df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCxVUKpMTEcN"
      },
      "source": [
        "# Ad hoc “predator server”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZF4XLFSBTKOM"
      },
      "outputs": [],
      "source": [
        "# Top level: wait for camo_xxx.jpeg files to appear, respond with find_xxx.txt\n",
        "def start_run(step = 0):\n",
        "    if step == 0:\n",
        "        print('Start run in', shared_directory )\n",
        "    else:\n",
        "        print('Continue run at step', step, ' in', shared_directory)\n",
        "    while True:\n",
        "        perform_step(step, shared_directory)\n",
        "        step += 1\n",
        "\n",
        "# Continue from from the last camo_xxx.jpeg file.\n",
        "def restart_run():\n",
        "    start_run(newest_file_from_other(shared_directory))\n",
        "\n",
        "# Single step: wait for camo file, write response, delete previous response.\n",
        "def perform_step(step, directory):\n",
        "    wait_for_reply(step, shared_directory)\n",
        "    write_response_file(step, shared_directory)\n",
        "    delete_find_file(step - 1, shared_directory)\n",
        "\n",
        "# Read image file for step, apply pre-trained model, write response file.\n",
        "def write_response_file(step, directory):\n",
        "    # Read image file and check for expected format.\n",
        "    image_pathname = make_camo_pathname(step, directory)\n",
        "    pixel_tensor = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "    assert df.check_pixel_tensor(pixel_tensor), ('wrong file format: ' +\n",
        "                                                 image_pathname)\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "\n",
        "    # model = Predator.get_population()[0]\n",
        "\n",
        "    # model = Predator.population[0]\n",
        "\n",
        "    # default_predator = population_of_predators[0]\n",
        "\n",
        "    # default_predator = Predator.population[0]\n",
        "    # model = default_predator.model\n",
        "\n",
        "    model = Predator.default_predator().model\n",
        "\n",
        "    # Run pre-trained model on new image.\n",
        "    prediction = model.predict(tf.convert_to_tensor([pixel_tensor]))[0]\n",
        "    ############################################################################\n",
        "    # Generate response file.\n",
        "    response_string = str(prediction[0]) + \" \" + str(prediction[1])\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(make_find_pathname(step, directory), 'w') as file:\n",
        "        file.write(response_string)\n",
        "    print('Wrote ' + \"'\" + response_string + \"'\",\n",
        "          'to response file', Path(make_find_pathname(step, directory)).name)\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "\n",
        "    # TODO 20220730 purely for testing -- delete me\n",
        "    opm = Predator.second_predator().model\n",
        "    print('\"other\" prediction:',\n",
        "          opm.predict(tf.convert_to_tensor([pixel_tensor]))[0])\n",
        "\n",
        "    # Predator learns from recent experience.\n",
        "    # fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
        "    # default_predator.fine_tune_predator(pixel_tensor, prediction, step, directory)\n",
        "    Predator.default_predator().fine_tune_predator(pixel_tensor, prediction,\n",
        "                                                   step, directory)\n",
        "    ############################################################################\n",
        "\n",
        "# Delete the given file, usually after having written the next one.\n",
        "def delete_find_file(step, directory):\n",
        "    # Why doesn't pathlib provide a Path.remove() method like os?\n",
        "    # TODO oh, missing_ok was added at pathlib version 3.8.\n",
        "    # Path(makeMyPathname(step, directory)).unlink(missing_ok=True)\n",
        "    p = Path(make_find_pathname(step, directory))\n",
        "    if p.exists():\n",
        "        p.unlink()\n",
        "\n",
        "# Delete any remaining file in commuications directory to start a new run.\n",
        "def clean_up_communication_directory():\n",
        "    def delete_directory_contents(directory_path):\n",
        "        for path in directory_path.iterdir():\n",
        "            print('Removing from communication directory:', path)\n",
        "            if path.is_dir():\n",
        "                delete_directory_contents(path)\n",
        "                path.rmdir()\n",
        "            else:\n",
        "                path.unlink()\n",
        "    delete_directory_contents(Path(shared_directory))\n",
        "\n",
        "# From pathname for file of given step number from the \"other\" agent.\n",
        "def make_camo_pathname(step, directory):\n",
        "    return directory + other_prefix + str(step) + other_suffix\n",
        "\n",
        "# Form pathname for \"find_xx.txt\" response file from \"this\" agent.\n",
        "def make_find_pathname(step, directory):\n",
        "    return directory + my_prefix + str(step) + my_suffix\n",
        "\n",
        "# Form pathname for \"prey_xx.txt\" ground truth file from \"other\" agent.\n",
        "def make_prey_pathname(step, directory):\n",
        "    return directory + 'prey_' + str(step) + '.txt'\n",
        "\n",
        "# Used to ping the comms directory when it seems hung.\n",
        "def write_ping_file(count, step, directory):\n",
        "    pn = directory + 'ping_cloud_' + str(step) + '.txt'\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(pn, 'w') as file:\n",
        "        file.write(str(count))\n",
        "    print('Ping comms: ', count, pn)\n",
        "\n",
        "# Wait until other agent's file for given step appears.\n",
        "def wait_for_reply(step, directory):\n",
        "    camo_pathname = Path(make_camo_pathname(step, directory))\n",
        "    camo_filename = camo_pathname.name\n",
        "    prey_pathname = Path(make_prey_pathname(step, directory))\n",
        "    prey_filename = prey_pathname.name\n",
        "    print('Waiting for', camo_filename, 'and', prey_filename, '...',\n",
        "          end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    # Loop until both files are present, waiting 1 second between tests.\n",
        "    test_count = 0\n",
        "    while not (is_file_present(camo_pathname) and\n",
        "               is_file_present(prey_pathname)):\n",
        "        time.sleep(1)\n",
        "        test_count += 1\n",
        "        if (test_count % 100) == 0:\n",
        "            write_ping_file(test_count, step, directory)\n",
        "    print(' done, elapsed time:', int(time.time() - start_time), 'seconds.')\n",
        "\n",
        "# Like fs::exists()\n",
        "def is_file_present(file):\n",
        "    result = False\n",
        "    verify_comms_directory_reachable()\n",
        "    filename = Path(file).name\n",
        "    directory = Path(file).parent\n",
        "    for i in directory.iterdir():\n",
        "        if i.name == filename:\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "# Returns the step number of the newest file from \"other\" in given directory.\n",
        "# (So if \"camo_573.jpeg\" is the only \"other\" file there, returns int 573)\n",
        "def newest_file_from_other(directory):\n",
        "    steps = [0]  # Default to zero in case dir is empty.\n",
        "    for filename in Path(directory).iterdir():\n",
        "        name = filename.name\n",
        "        if other_prefix == name[0:len(other_prefix)]:\n",
        "            steps.append(int(name.split(\".\")[0].split(\"_\")[1]))\n",
        "    return max(steps)\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220728 maybe fine_tune_images, fine_tune_labels, etc. should be\n",
        "# associated with Predator class, but not instance, like c++ class static member.\n",
        "\n",
        "# # Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
        "# # https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
        "# # of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
        "# # max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
        "# max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
        "# # List of \"pixel tensors\".\n",
        "# fine_tune_images = []\n",
        "# # List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
        "# fine_tune_labels = []\n",
        "\n",
        "# # Keep track of how often selected prey is nearest center:\n",
        "# nearest_center = 0\n",
        "\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220728 fine_tune_predator() should become a method of Predator class.\n",
        "\n",
        "# # Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
        "# # training set. Assume they were \"near misses\" and so training label is actual\n",
        "# # (ground truth) center of disk nearest prediction. Keep a max number of old\n",
        "# # steps to allow gradually forgetting the earliest part of the run.\n",
        "# def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
        "#     # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
        "#     xy3 = read_3_centers_from_file(step, directory)\n",
        "#     sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
        "\n",
        "#     # Accumulate the most recent \"max_training_set_size\" training samples.\n",
        "#     global fine_tune_images\n",
        "#     global fine_tune_labels\n",
        "#     fine_tune_images.append(pixel_tensor)\n",
        "#     fine_tune_labels.append(sorted_xy3)\n",
        "\n",
        "#     # If training set has become too large, slice off first element of each.\n",
        "#     if len(fine_tune_images) > max_training_set_size:\n",
        "#         fine_tune_images = fine_tune_images[1:]\n",
        "#         fine_tune_labels = fine_tune_labels[1:]\n",
        "\n",
        "#     # keep track of how often selected prey is nearest center:\n",
        "#     temp = xy3.copy()  # needed?\n",
        "#     sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
        "#     if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
        "#         global nearest_center\n",
        "#         nearest_center += 1\n",
        "#     print('  nearest_center:',\n",
        "#           str(int(100 * float(nearest_center) / (step + 1))) + '%',\n",
        "#           '(nearest_center =', nearest_center, ', steps =', step + 1, ')')\n",
        "\n",
        "#     # Convert training data list to np arrays\n",
        "#     images_array = np.array(fine_tune_images)\n",
        "#     labels_array = np.array([x[0] for x in fine_tune_labels])\n",
        "#     print('images_array.shape =', images_array.shape)\n",
        "#     print('labels_array.shape =', labels_array.shape)\n",
        "\n",
        "# \t# skip fine-tuning until dataset is large enough (10% of max size).\n",
        "#     if images_array.shape[0] > (max_training_set_size * 0.1):\n",
        "#         # Do fine-tuning training step using data accumulated during run.\n",
        "#         history = model.fit(x=images_array, y=labels_array)\n",
        "#         # Keep log of in_disk metric:\n",
        "#         write_in_disk_log(step, history)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# Read ground truth prey center location data provided in \"prey_n.txt\" file.\n",
        "def read_3_centers_from_file(step, directory):\n",
        "    # Read contents of file as string.\n",
        "    verify_comms_directory_reachable()\n",
        "    with open(make_prey_pathname(step, directory), 'r') as file:\n",
        "        prey_centers_string = file.read()\n",
        "    # Split string at whitespace, map to 6 floats, reshape into 3 xy pairs.\n",
        "    # (TODO could probably be rewritten cleaner with \"list comprehension\")\n",
        "    array = np.reshape(list(map(float, prey_centers_string.split())), (3, 2))\n",
        "    return array.tolist()\n",
        "\n",
        "# Keep log of in_disk metric.\n",
        "def write_in_disk_log(step, history):\n",
        "    if step % 10 == 0:\n",
        "        in_disk = history.history[\"in_disk\"][0]\n",
        "        pathname = shared_directory + 'in_disk_log.csv'\n",
        "        verify_comms_directory_reachable()\n",
        "        with open(pathname, 'a') as file:\n",
        "            if step == 0:\n",
        "                file.write('step,in_disk\\n')\n",
        "            file.write(str(step) + ',' + \"{:.4f}\".format(in_disk) + '\\n')\n",
        "\n",
        "# Just wait in retry loop if shared \"comms\" directory become unreachable.\n",
        "# Probably will return shortly, better to wait than signal a file error.\n",
        "# (This is called from places with a local \"directory\" but it uses global value.)\n",
        "def verify_comms_directory_reachable():\n",
        "    seconds = 0\n",
        "    # shared_directory_pathname = Path(shared_directory)\n",
        "    # while not shared_directory_pathname.is_dir():\n",
        "    while not Path(shared_directory).is_dir():\n",
        "        print(\"Shared “comms” directory,\", shared_directory, \n",
        "              \"has been inaccessible for\", seconds, \"seconds.\")\n",
        "        time.sleep(1)  # wait 1 sec\n",
        "        seconds += 1\n",
        "\n",
        "# Given 3 prey positions (\"xy3\"), sort them by proximity to \"point\" (prediction)\n",
        "def sort_xy3_by_proximity_to_point(xy3, point):\n",
        "    # print('xy3 =', xy3)\n",
        "    xy3_plus_distance = [[df.dist2d(xy, point), xy] for xy in xy3]\n",
        "    # print('xy3_plus_distance =', xy3_plus_distance)\n",
        "    sorted_xy3_plus_key = sorted(xy3_plus_distance, key=lambda x: x[0])\n",
        "    # print('sorted_xy3_plus_key =', sorted_xy3_plus_key)\n",
        "    sorted_xy3 = [x[1] for x in sorted_xy3_plus_key]\n",
        "    # print('sorted_xy3 =', sorted_xy3)\n",
        "    return sorted_xy3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDtbk88sVGxk"
      },
      "source": [
        "# Read pre-trained model\n",
        "\n",
        "As I integrate this into the Predator class, this is no longer “Read pre-trained model” but more like “Some utilities for reading the pre-trained model”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iLVIRi_vU9gN"
      },
      "outputs": [],
      "source": [
        "# Read pre-trained TensorFlow \"predator vision\" model.\n",
        "\n",
        "# print('Reading pre-trained model from:', trained_model)\n",
        "\n",
        "# ad hoc workaround suggested on https://stackoverflow.com/q/66408995/1991373\n",
        "#\n",
        "# dependencies = {\n",
        "#     'hamming_loss': tfa.metrics.HammingLoss(mode=\"multilabel\", name=\"hamming_loss\"),\n",
        "#     'attention': attention(return_sequences=True)\n",
        "# }\n",
        "#\n",
        "# dependencies = {\n",
        "#     'valid_accuracy': ValidAccuracy\n",
        "# }\n",
        "\n",
        "# Calculates RELATIVE disk radius on the fly -- rewrite later.\n",
        "def fcd_disk_radius():\n",
        "    return (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "# Given two tensors of 2d point coordinates, return a tensor of the Cartesian\n",
        "# distance between corresponding points in the input tensors.\n",
        "def corresponding_distances(y_true, y_pred):\n",
        "    true_pos_x, true_pos_y = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
        "    pred_pos_x, pred_pos_y = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
        "    dx = true_pos_x - pred_pos_x\n",
        "    dy = true_pos_y - pred_pos_y\n",
        "    distances = tf.sqrt(tf.square(dx) + tf.square(dy))\n",
        "    return distances\n",
        "\n",
        "# 20211231 copied from Find_Concpocuous_Disk\n",
        "def in_disk(y_true, y_pred):\n",
        "    distances = corresponding_distances(y_true, y_pred)\n",
        "    # relative_disk_radius = (float(fcd_disk_size) / float(fcd_image_size)) / 2\n",
        "\n",
        "    # From https://stackoverflow.com/a/42450565/1991373\n",
        "    # Boolean tensor marking where distances are less than relative_disk_radius.\n",
        "    # insides = tf.less(distances, relative_disk_radius)\n",
        "    insides = tf.less(distances, fcd_disk_radius())\n",
        "    map_to_zero_or_one = tf.cast(insides, tf.int32)\n",
        "    return map_to_zero_or_one\n",
        "\n",
        "dependencies = { 'in_disk': in_disk }\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220726 change for Predator class.\n",
        "\n",
        "# model = keras.models.load_model(trained_model, custom_objects=dependencies)\n",
        "\n",
        "def read_default_pre_trained_model():\n",
        "    print('Reading pre-trained model from:', trained_model)\n",
        "    return keras.models.load_model(trained_model, custom_objects=dependencies)\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predator class"
      ],
      "metadata": {
        "id": "RgRdzOk5Vtmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO 20220729 having trouble defining this as a \"class variable\" (c++ static)\n",
        "# so moving it out here for now.\n",
        "\n",
        "# population_of_predators = []\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# TODO switch to using Python standard \"\"\"doc strings\"\"\" for methods below?\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220724 define for Predator, we want to have a population of them.\n",
        "\n",
        "class Predator:\n",
        "    \"\"\"Represents a Predator in the camouflage simulation. It has a CNN-based\n",
        "       model of visual hunting that identified the position of likely prey.\"\"\"\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220729 prototype storing what had been the global predator model\n",
        "    # with one stored in Predator class.\n",
        "    # untested\n",
        "\n",
        "    population = []\n",
        "\n",
        "    # # Static class function, returns global list of all Predators.\n",
        "    # @ staticmethod\n",
        "    # def get_population():\n",
        "    #     print('in get_population(), size is', len(self.population))\n",
        "    #     return self.population\n",
        "\n",
        "    # # Add or remove a Predator instance from the global population.\n",
        "    # # def add_to_population(self):\n",
        "    # #     population.append(self)\n",
        "    # def remove_from_population(self):\n",
        "    #     population.remove(self)\n",
        "    ############################################################################\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        # Each Predator has its own copy of a prey-finding CNN-based model.\n",
        "        self.model = []\n",
        "        ########################################################################\n",
        "        # TODO 20220729 \n",
        "        # population.append(self)\n",
        "        # self.population.append(self)\n",
        "        # global population_of_predators\n",
        "        # population_of_predators.append(self)\n",
        "        global population_of_predators\n",
        "        self.population.append(self)\n",
        "        ########################################################################\n",
        "\n",
        "    def initialize_to_pre_trained_model(self):\n",
        "        self.model = read_default_pre_trained_model()\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220730 rather than define this concept elsewhere, move it inside,\n",
        "    #               even if it is transitional/experimental.\n",
        "    # def default_predator(self):\n",
        "    #     return self.population[0]\n",
        "    # def default_predator():\n",
        "    #     return self.population[0]\n",
        "    # def default_predator():\n",
        "    #     return population[0]\n",
        "\n",
        "    def default_predator():\n",
        "        return Predator.population[0]\n",
        "    \n",
        "    def second_predator():\n",
        "        return Predator.population[1]\n",
        "    \n",
        "    ############################################################################\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220728 maybe fine_tune_images, fine_tune_labels, etc. should be\n",
        "    # associated with Predator class, but not instance, like c++ class static member.\n",
        "    #\n",
        "    # Arguably, this managing of the dataset for fine tuning ought to be inside\n",
        "    # its own class. But for now it will just be inline class attributes of Predator. \n",
        "\n",
        "    # Accumulated a new “training set” of the most recent N steps seen so far. (See\n",
        "    # https://cwreynolds.github.io/TexSyn/#20220421 and ...#20220424 for discussion\n",
        "    # of this parameter. Had been 1, then 100, then 200, then finally, infinity.) \n",
        "    # max_training_set_size = float('inf') # keep ALL steps in training set, use GPU.\n",
        "    max_training_set_size = 500 # Try smaller again, \"yellow flowers\" keeps failing.\n",
        "    # List of \"pixel tensors\".\n",
        "    fine_tune_images = []\n",
        "    # List of xy3 [[x,y],[x,y],[x,y]] for 3 prey centers.\n",
        "    fine_tune_labels = []\n",
        "\n",
        "    # Keep track of how often selected prey is nearest center:\n",
        "    nearest_center = 0\n",
        "\n",
        "    ############################################################################\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO 20220728 fine_tune_predator() should become a method of Predator class.\n",
        "    # Maybe it should be called just fine_tune(), Predator.fine_tune()\n",
        "\n",
        "    # Apply fine-tuning to (originally pre-trained) predator. Use recent steps as\n",
        "    # training set. Assume they were \"near misses\" and so training label is actual\n",
        "    # (ground truth) center of disk nearest prediction. Keep a max number of old\n",
        "    # steps to allow gradually forgetting the earliest part of the run.\n",
        "    # def fine_tune_predator(pixel_tensor, prediction, step, directory):\n",
        "    def fine_tune_predator(self, pixel_tensor, prediction, step, directory):\n",
        "        # Assume the predator was \"aiming for\" that one but missed by a bit.\n",
        "        xy3 = read_3_centers_from_file(step, directory)\n",
        "        sorted_xy3 = sort_xy3_by_proximity_to_point(xy3, prediction)\n",
        "\n",
        "        # Accumulate the most recent \"max_training_set_size\" training samples.\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # global fine_tune_images\n",
        "        # global fine_tune_labels\n",
        "        # fine_tune_images.append(pixel_tensor)\n",
        "        # fine_tune_labels.append(sorted_xy3)\n",
        "        self.fine_tune_images.append(pixel_tensor)\n",
        "        self.fine_tune_labels.append(sorted_xy3)\n",
        "        ########################################################################\n",
        "\n",
        "        # If training set has become too large, slice off first element of each.\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # if len(fine_tune_images) > max_training_set_size:\n",
        "        #     fine_tune_images = fine_tune_images[1:]\n",
        "        #     fine_tune_labels = fine_tune_labels[1:]\n",
        "        if len(self.fine_tune_images) > self.max_training_set_size:\n",
        "            self.fine_tune_images = self.fine_tune_images[1:]\n",
        "            self.fine_tune_labels = self.fine_tune_labels[1:]\n",
        "        ########################################################################\n",
        "\n",
        "        # keep track of how often selected prey is nearest center:\n",
        "        temp = xy3.copy()  # needed?\n",
        "        sorted_by_dist_to_center = sort_xy3_by_proximity_to_point(temp, [0.5, 0.5])\n",
        "        if sorted_by_dist_to_center[0] == sorted_xy3[0]:\n",
        "            global nearest_center\n",
        "            ####################################################################\n",
        "            # TODO 20220729\n",
        "            # nearest_center += 1\n",
        "            self.nearest_center += 1\n",
        "            ####################################################################\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # print('  nearest_center:',\n",
        "        #       str(int(100 * float(nearest_center) / (step + 1))) + '%',\n",
        "        #       '(nearest_center =', nearest_center, ', steps =', step + 1, ')')\n",
        "        print('  nearest_center:',\n",
        "              str(int(100 * float(self.nearest_center) / (step + 1))) + '%',\n",
        "              '(nearest_center =', self.nearest_center, ', steps =', step + 1, ')')\n",
        "        ########################################################################\n",
        "\n",
        "        # Convert training data list to np arrays\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # images_array = np.array(fine_tune_images)\n",
        "        # labels_array = np.array([x[0] for x in fine_tune_labels])\n",
        "        images_array = np.array(self.fine_tune_images)\n",
        "        labels_array = np.array([x[0] for x in self.fine_tune_labels])\n",
        "        ########################################################################\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO 20220730\n",
        "        # print('images_array.shape =', images_array.shape)\n",
        "        # print('labels_array.shape =', labels_array.shape)\n",
        "\n",
        "        print('images_array.shape =', images_array.shape,\n",
        "              '-- labels_array.shape =', labels_array.shape)\n",
        "\n",
        "        ########################################################################\n",
        "\n",
        "    \t# skip fine-tuning until dataset is large enough (10% of max size).\n",
        "        ########################################################################\n",
        "        # TODO 20220729\n",
        "        # if images_array.shape[0] > (max_training_set_size * 0.1):\n",
        "        #     # Do fine-tuning training step using data accumulated during run.\n",
        "        #     history = model.fit(x=images_array, y=labels_array)\n",
        "        #     # Keep log of in_disk metric:\n",
        "        #     write_in_disk_log(step, history)\n",
        "        if images_array.shape[0] > (self.max_training_set_size * 0.1):\n",
        "            # Do fine-tuning training step using data accumulated during run.\n",
        "            history = self.model.fit(x=images_array, y=labels_array)\n",
        "            # Keep log of in_disk metric:\n",
        "            write_in_disk_log(step, history)\n",
        "        ########################################################################\n",
        "\n",
        "    # TODO 20220730 try running second model\n",
        "    def jiggle_model(self):\n",
        "        weight_perturbation(self.model)\n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "################################################################################\n",
        "# TODO 20220730\n",
        "# Utility from https://stackoverflow.com/a/64542651/1991373\n",
        "\n",
        "def weight_perturbation(model):\n",
        "    \"\"\"Add noise to all weights in a Keras model.\"\"\"\n",
        "    for layer in model.layers:\n",
        "        trainable_weights = layer.trainable_variables\n",
        "        for weight in trainable_weights:\n",
        "            random_weights = tf.random.uniform(tf.shape(weight),\n",
        "                                               # 1e-4, 1e-5,\n",
        "                                               0, 0.001,\n",
        "                                               dtype=tf.float32)\n",
        "            weight.assign_add(random_weights)\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# TODO 20220729 prototype storing what had been the global predator model with\n",
        "# one stored in Predator class.\n",
        "\n",
        "test_predator = Predator()\n",
        "test_predator.initialize_to_pre_trained_model()\n",
        "\n",
        "# TODO 20220730 try running second model\n",
        "second_predator = Predator()\n",
        "second_predator.initialize_to_pre_trained_model()\n",
        "second_predator.jiggle_model()\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "a4sR8eHOV2pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31fae9a-4b88-4295-a04d-a8c11a476dbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pre-trained model from: /content/drive/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n",
            "Reading pre-trained model from: /content/drive/My Drive/PredatorEye/saved_models/20220321_1711_FCD6_rc4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itBD_Ve0lEYB"
      },
      "source": [
        "# Run test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZQLL52Sk-X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24f3d22-6f92-4297-bd09-b8fc843407a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start run in /content/drive/My Drive/PredatorEye/evo_camo_vs_static_fcd/\n",
            "Waiting for camo_0.png and prey_0.txt ... done, elapsed time: 36 seconds.\n",
            "Wrote '0.35675594 0.6136136' to response file find_0.txt\n",
            "\"other\" prediction: [0.35496944 0.6173679 ]\n",
            "  nearest_center: 0% (nearest_center = 0 , steps = 1 )\n",
            "images_array.shape = (1, 128, 128, 3) , labels_array.shape = (1, 2)\n",
            "Waiting for camo_1.png and prey_1.txt ... done, elapsed time: 18 seconds.\n",
            "Wrote '0.5495125 0.34157526' to response file find_1.txt\n",
            "\"other\" prediction: [0.5503588  0.34200406]\n",
            "  nearest_center: 50% (nearest_center = 1 , steps = 2 )\n",
            "images_array.shape = (2, 128, 128, 3) , labels_array.shape = (2, 2)\n",
            "Waiting for camo_2.png and prey_2.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.7734213 0.33669877' to response file find_2.txt\n",
            "\"other\" prediction: [0.7857189  0.33577794]\n",
            "  nearest_center: 33% (nearest_center = 1 , steps = 3 )\n",
            "images_array.shape = (3, 128, 128, 3) , labels_array.shape = (3, 2)\n",
            "Waiting for camo_3.png and prey_3.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_3.txt\n",
            "\"other\" prediction: [0.56506634 0.5750975 ]\n",
            "  nearest_center: 25% (nearest_center = 1 , steps = 4 )\n",
            "images_array.shape = (4, 128, 128, 3) , labels_array.shape = (4, 2)\n",
            "Waiting for camo_4.png and prey_4.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.35539943 0.75489753' to response file find_4.txt\n",
            "\"other\" prediction: [0.3543401 0.7703104]\n",
            "  nearest_center: 20% (nearest_center = 1 , steps = 5 )\n",
            "images_array.shape = (5, 128, 128, 3) , labels_array.shape = (5, 2)\n",
            "Waiting for camo_5.png and prey_5.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.54594105 0.7341972' to response file find_5.txt\n",
            "\"other\" prediction: [0.5471174 0.7433977]\n",
            "  nearest_center: 16% (nearest_center = 1 , steps = 6 )\n",
            "images_array.shape = (6, 128, 128, 3) , labels_array.shape = (6, 2)\n",
            "Waiting for camo_6.png and prey_6.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.7391924 0.34770697' to response file find_6.txt\n",
            "\"other\" prediction: [0.7491262  0.35043365]\n",
            "  nearest_center: 14% (nearest_center = 1 , steps = 7 )\n",
            "images_array.shape = (7, 128, 128, 3) , labels_array.shape = (7, 2)\n",
            "Waiting for camo_7.png and prey_7.txt ... done, elapsed time: 41 seconds.\n",
            "Wrote '0.46341926 0.5970082' to response file find_7.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 25% (nearest_center = 2 , steps = 8 )\n",
            "images_array.shape = (8, 128, 128, 3) , labels_array.shape = (8, 2)\n",
            "Waiting for camo_8.png and prey_8.txt ... done, elapsed time: 41 seconds.\n",
            "Wrote '0.7326103 0.36356786' to response file find_8.txt\n",
            "\"other\" prediction: [0.74356234 0.36456266]\n",
            "  nearest_center: 33% (nearest_center = 3 , steps = 9 )\n",
            "images_array.shape = (9, 128, 128, 3) , labels_array.shape = (9, 2)\n",
            "Waiting for camo_9.png and prey_9.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.23991701 0.74159425' to response file find_9.txt\n",
            "\"other\" prediction: [0.23470813 0.76400614]\n",
            "  nearest_center: 30% (nearest_center = 3 , steps = 10 )\n",
            "images_array.shape = (10, 128, 128, 3) , labels_array.shape = (10, 2)\n",
            "Waiting for camo_10.png and prey_10.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.25652066 0.3608734' to response file find_10.txt\n",
            "\"other\" prediction: [0.266613   0.36599302]\n",
            "  nearest_center: 27% (nearest_center = 3 , steps = 11 )\n",
            "images_array.shape = (11, 128, 128, 3) , labels_array.shape = (11, 2)\n",
            "Waiting for camo_11.png and prey_11.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_11.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 33% (nearest_center = 4 , steps = 12 )\n",
            "images_array.shape = (12, 128, 128, 3) , labels_array.shape = (12, 2)\n",
            "Waiting for camo_12.png and prey_12.txt ... done, elapsed time: 19 seconds.\n",
            "Wrote '0.72425073 0.47885734' to response file find_12.txt\n",
            "\"other\" prediction: [0.7346065  0.48527765]\n",
            "  nearest_center: 38% (nearest_center = 5 , steps = 13 )\n",
            "images_array.shape = (13, 128, 128, 3) , labels_array.shape = (13, 2)\n",
            "Waiting for camo_13.png and prey_13.txt ... done, elapsed time: 41 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_13.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 42% (nearest_center = 6 , steps = 14 )\n",
            "images_array.shape = (14, 128, 128, 3) , labels_array.shape = (14, 2)\n",
            "Waiting for camo_14.png and prey_14.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.77827805 0.54000145' to response file find_14.txt\n",
            "\"other\" prediction: [0.79005855 0.5501884 ]\n",
            "  nearest_center: 40% (nearest_center = 6 , steps = 15 )\n",
            "images_array.shape = (15, 128, 128, 3) , labels_array.shape = (15, 2)\n",
            "Waiting for camo_15.png and prey_15.txt ... done, elapsed time: 19 seconds.\n",
            "Wrote '0.22599578 0.3696579' to response file find_15.txt\n",
            "\"other\" prediction: [0.2261143 0.3747724]\n",
            "  nearest_center: 37% (nearest_center = 6 , steps = 16 )\n",
            "images_array.shape = (16, 128, 128, 3) , labels_array.shape = (16, 2)\n",
            "Waiting for camo_16.png and prey_16.txt ... done, elapsed time: 20 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_16.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 41% (nearest_center = 7 , steps = 17 )\n",
            "images_array.shape = (17, 128, 128, 3) , labels_array.shape = (17, 2)\n",
            "Waiting for camo_17.png and prey_17.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.5579996 0.77018243' to response file find_17.txt\n",
            "\"other\" prediction: [0.5597468  0.79386926]\n",
            "  nearest_center: 38% (nearest_center = 7 , steps = 18 )\n",
            "images_array.shape = (18, 128, 128, 3) , labels_array.shape = (18, 2)\n",
            "Waiting for camo_18.png and prey_18.txt ... done, elapsed time: 41 seconds.\n",
            "Wrote '0.6987196 0.57008195' to response file find_18.txt\n",
            "\"other\" prediction: [0.71935344 0.5729869 ]\n",
            "  nearest_center: 42% (nearest_center = 8 , steps = 19 )\n",
            "images_array.shape = (19, 128, 128, 3) , labels_array.shape = (19, 2)\n",
            "Waiting for camo_19.png and prey_19.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.5588621 0.8137406' to response file find_19.txt\n",
            "\"other\" prediction: [0.5604075 0.8256695]\n",
            "  nearest_center: 40% (nearest_center = 8 , steps = 20 )\n",
            "images_array.shape = (20, 128, 128, 3) , labels_array.shape = (20, 2)\n",
            "Waiting for camo_20.png and prey_20.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.60150415 0.58076155' to response file find_20.txt\n",
            "\"other\" prediction: [0.5961473  0.58887905]\n",
            "  nearest_center: 42% (nearest_center = 9 , steps = 21 )\n",
            "images_array.shape = (21, 128, 128, 3) , labels_array.shape = (21, 2)\n",
            "Waiting for camo_21.png and prey_21.txt ... done, elapsed time: 39 seconds.\n",
            "Wrote '0.3994745 0.219756' to response file find_21.txt\n",
            "\"other\" prediction: [0.3946321  0.22494724]\n",
            "  nearest_center: 40% (nearest_center = 9 , steps = 22 )\n",
            "images_array.shape = (22, 128, 128, 3) , labels_array.shape = (22, 2)\n",
            "Waiting for camo_22.png and prey_22.txt ... done, elapsed time: 82 seconds.\n",
            "Wrote '0.3842281 0.22251634' to response file find_22.txt\n",
            "\"other\" prediction: [0.37565917 0.2288886 ]\n",
            "  nearest_center: 39% (nearest_center = 9 , steps = 23 )\n",
            "images_array.shape = (23, 128, 128, 3) , labels_array.shape = (23, 2)\n",
            "Waiting for camo_23.png and prey_23.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.245709 0.49472064' to response file find_23.txt\n",
            "\"other\" prediction: [0.24694294 0.50897235]\n",
            "  nearest_center: 41% (nearest_center = 10 , steps = 24 )\n",
            "images_array.shape = (24, 128, 128, 3) , labels_array.shape = (24, 2)\n",
            "Waiting for camo_24.png and prey_24.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.24558076 0.34881964' to response file find_24.txt\n",
            "\"other\" prediction: [0.2455791  0.35445768]\n",
            "  nearest_center: 44% (nearest_center = 11 , steps = 25 )\n",
            "images_array.shape = (25, 128, 128, 3) , labels_array.shape = (25, 2)\n",
            "Waiting for camo_25.png and prey_25.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.36382836 0.7257784' to response file find_25.txt\n",
            "\"other\" prediction: [0.36723688 0.7372308 ]\n",
            "  nearest_center: 46% (nearest_center = 12 , steps = 26 )\n",
            "images_array.shape = (26, 128, 128, 3) , labels_array.shape = (26, 2)\n",
            "Waiting for camo_26.png and prey_26.txt ... done, elapsed time: 66 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_26.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 48% (nearest_center = 13 , steps = 27 )\n",
            "images_array.shape = (27, 128, 128, 3) , labels_array.shape = (27, 2)\n",
            "Waiting for camo_27.png and prey_27.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.5317501 0.5775294' to response file find_27.txt\n",
            "\"other\" prediction: [0.52367127 0.586695  ]\n",
            "  nearest_center: 46% (nearest_center = 13 , steps = 28 )\n",
            "images_array.shape = (28, 128, 128, 3) , labels_array.shape = (28, 2)\n",
            "Waiting for camo_28.png and prey_28.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.78693205 0.37908238' to response file find_28.txt\n",
            "\"other\" prediction: [0.79723334 0.38545287]\n",
            "  nearest_center: 48% (nearest_center = 14 , steps = 29 )\n",
            "images_array.shape = (29, 128, 128, 3) , labels_array.shape = (29, 2)\n",
            "Waiting for camo_29.png and prey_29.txt ... done, elapsed time: 40 seconds.\n",
            "Wrote '0.79043007 0.3583076' to response file find_29.txt\n",
            "\"other\" prediction: [0.80408573 0.3596809 ]\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO 20220728 refactoring for Predator class.\n",
        "\n",
        "# Keep track of how often selected prey is nearest center:\n",
        "# nearest_center = 0\n",
        "Predator.nearest_center = 0\n",
        "# Predator.population = []\n",
        "\n",
        "# TODO maybe a reset() method?\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Flush out obsolete files in comms directory.\n",
        "clean_up_communication_directory()\n",
        "\n",
        "# Start fresh run defaulting to step 0.\n",
        "start_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h7-m6IIu6i4"
      },
      "outputs": [],
      "source": [
        "# Normally start from step 0, or if an \"other\" file exists\n",
        "# (eg 'camo_123.jpeg') then restart from that point.\n",
        "\n",
        "# restart_run()"
      ]
    }
  ]
}