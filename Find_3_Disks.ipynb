{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find_3_Disks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bdf0a0e03ac04232a0344bcfb51b88a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b061c7e8f8a446ad87b7645ba0a599ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3ba8e9afed344c3b23d1cab26a032a5",
              "IPY_MODEL_05c0f2f14400486a945ca1650ce80615",
              "IPY_MODEL_bf52863177d9404fad2f6e4fc0645a46"
            ]
          }
        },
        "b061c7e8f8a446ad87b7645ba0a599ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3ba8e9afed344c3b23d1cab26a032a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56da98ac9bb74d2892a7892bc6e2ff36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58ba5a3b45cc4e6490e6c29b04985e29"
          }
        },
        "05c0f2f14400486a945ca1650ce80615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_edb816385f434ff3b683e1f80a5d1c1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84a0c1d59c714cc0a316dc4673188483"
          }
        },
        "bf52863177d9404fad2f6e4fc0645a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08e47944c3cf4c1aa2c829dd6cedeaea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20000/20000 [00:52&lt;00:00, 515.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_939b83438cfb46a3839904e8869507c1"
          }
        },
        "56da98ac9bb74d2892a7892bc6e2ff36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58ba5a3b45cc4e6490e6c29b04985e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edb816385f434ff3b683e1f80a5d1c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84a0c1d59c714cc0a316dc4673188483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08e47944c3cf4c1aa2c829dd6cedeaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "939b83438cfb46a3839904e8869507c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Find 3 Disks\n",
        "Given an image with a background texture, and three overlaid texured disks, predict the centerpoint of the labeled “most concpicuous disk.”\n",
        "\n",
        "(**Note:** on February 16, 2022 I saved a version of this to `graveyard/Find_3_Disks_before_generators.ipynb`)"
      ],
      "metadata": {
        "id": "0qtAzmipHZMh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oROsyXIQrzSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19569b7c-b250-4e19-ba30-34c530369dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import PIL\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "import os.path\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "# Import DiskFind utilities for PredatorEye.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/PredatorEye/shared_code/')\n",
        "import DiskFind as df\n",
        "\n",
        "df.set_global_random_seed(20220108)\n",
        "model_save_directory = '/content/drive/My Drive/PredatorEye/saved_models/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define uniform texture dataset"
      ],
      "metadata": {
        "id": "tMa0B_-6IIFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def MakeUniformTextureDataset(dataset_size, image_size, image_depth):\n",
        "def make_uniform_dataset(dataset_size, image_size, image_depth):\n",
        "    dataset_shape = (dataset_size, image_size, image_size, image_depth)\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i in tqdm(range(dataset_size)):\n",
        "        # (image, label) = generateUniformExample(image_size, image_depth)\n",
        "        (image, label) = generate_uniform_example(image_size, image_depth)\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "        # # TODO TEMP -- Draw image for debugging\n",
        "        # if ((i % 50) == 0) and (i < (50 * 5)): df.draw_image(image)\n",
        "    return (images, labels)\n",
        "\n",
        "# blah blah\n",
        "# return an image (pixel tensor) and a label as (x, y) tensor\n",
        "# def generateUniformExample(image_size, image_depth):\n",
        "def generate_uniform_example(image_size, image_depth):\n",
        "    bg_color = np.random.random_sample(image_depth)\n",
        "    fg_color = np.random.random_sample(image_depth)\n",
        "    disk_radius = image_size * df.relative_disk_radius()\n",
        "    image_shape = (image_size, image_size, image_depth)\n",
        "    image = np.full(image_shape, bg_color, dtype=np.float32)\n",
        "\n",
        "    # Find 3 non-overlapping disk positions inside image.\n",
        "    def random_center():\n",
        "        s = image_size - (2 * disk_radius)\n",
        "        return (np.random.random_sample(2) * s) + disk_radius\n",
        "    centers = [random_center()]\n",
        "    min_dist = 3 * disk_radius\n",
        "    while len(centers) < 3:\n",
        "        c = random_center()\n",
        "        all_ok = True\n",
        "        for o in centers:\n",
        "            if (df.dist2d(c, o) < min_dist):\n",
        "                all_ok = False\n",
        "        if (all_ok):\n",
        "            centers.append(c)\n",
        "\n",
        "    # Draw soft-eged disk with given centerpoint and color.\n",
        "    def draw_disk(center, color):\n",
        "        cx = int(center[0])\n",
        "        cy = int(center[1])\n",
        "        dr = int(disk_radius)\n",
        "        for x in range(cx - dr, cx + dr + 1):\n",
        "            for y in range(cy - dr, cy + dr + 1):\n",
        "                d = math.sqrt(math.pow(x - cx, 2) + math.pow(y - cy, 2))\n",
        "                if (d <= dr):\n",
        "                    blend = df.spot_utility((x, y), center, dr * 0.85, dr)\n",
        "                    image[x, y, :] = df.interpolate(blend, bg_color, color) \n",
        "\n",
        "    # Draw 3 soft-edged disks, with colors progressively more like background.\n",
        "    draw_disk(centers[0], fg_color)\n",
        "    draw_disk(centers[1], df.interpolate(0.33, fg_color, bg_color))\n",
        "    draw_disk(centers[2], df.interpolate(0.66, fg_color, bg_color))\n",
        "\n",
        "    # return image\n",
        "    # print('centers[0] =', centers[0])\n",
        "    # print('type(centers[0]) =', type(centers[0]))\n",
        "    label = centers[0] / image_size\n",
        "\n",
        "    # TODO When I visualized the labels, they appeared xy flipped\n",
        "    #      trying \"unflipping them\"\n",
        "    label = np.array((label[1], label[0]))\n",
        "\n",
        "    return (image, label)"
      ],
      "metadata": {
        "id": "pdjCCGblIGdW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reader for complex dataset"
      ],
      "metadata": {
        "id": "SLmzNXRO6J5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define complex texture (photo plus synthetic) dataset\n",
        "\n",
        "# 20220130 this structure (copied from above) is wrong.\n",
        "# We want to read the dir in the main function.\n",
        "# the \"per filename\" function could later be expanded to do amplification\n",
        "# if so, should return lists, which would need to be concatenated in caller.\n",
        "\n",
        "# # temp for prototyping\n",
        "# directory_pathname = '/content/drive/My Drive/PredatorEye/f3d_training_set/'\n",
        "\n",
        "# # \"Amplify\" dataset by adding one modified version of each precomputed image\n",
        "# amplify_2x = True\n",
        "\n",
        "# def make_complex_dataset():\n",
        "def make_complex_dataset(directory_pathname =\n",
        "                         '/content/drive/My Drive/PredatorEye/f3d_training_set/',\n",
        "                         amplify_2x = True):\n",
        "\n",
        "    directory_contents = listdir(directory_pathname)\n",
        "\n",
        "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
        "    # size_limit = 50\n",
        "    # print('Limit complex dataset size to', size_limit)\n",
        "    # directory_contents = directory_contents[0:size_limit]\n",
        "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in tqdm(directory_contents):\n",
        "        image_pathname = os.path.join(directory_pathname, filename)\n",
        "        (image, label) = make_complex_example(image_pathname)\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "        if amplify_2x:\n",
        "            (image, label) = modify_complex_example(image, label)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "    return (images, labels)\n",
        "\n",
        "# Read image file at given pathname, pre-process for use in training model.\n",
        "def make_complex_example(image_pathname):\n",
        "    # Read image file.\n",
        "    pixels = df.read_image_file_as_pixel_tensor(image_pathname)\n",
        "    # Check for expected format.\n",
        "    assert df.check_pixel_tensor(pixels), 'wrong file format: ' + image_pathname    \n",
        "    # Parse disk center position from file name.\n",
        "    filename = os.path.basename(image_pathname)\n",
        "    center_position = df.fcd_normalized_xy(filename, pixels)\n",
        "    return (pixels, center_position)\n",
        "\n",
        "# Make modified copy of one traing example (as a pixel tensor and xy label).\n",
        "# (Specifically: invert brighness, mirror horizontally, rotate 1/4, 1/2, or 3/4)\n",
        "def modify_complex_example(image, label):\n",
        "\n",
        "    def center_rot90(cp): return (cp[1], 0.5 - (cp[0] - 0.5))\n",
        "    def center_flip(cp): return (0.5 - (cp[0] - 0.5), cp[1])\n",
        "\n",
        "    # invert brighness of image:\n",
        "    image = 1 - image\n",
        "\n",
        "    # mirror horizontally\n",
        "    scaled_pixels = np.flip(image, axis=1)\n",
        "    label = center_flip(label)\n",
        "\n",
        "    # Rotate one of: 1/4, 1/2, or 3/4\n",
        "    n = random.randrange(1, 4)\n",
        "    for i in range(n):\n",
        "        # image = np.rot90(image, k=1, axes=(0, 1))\n",
        "        image = np.rot90(image, k=1, axes=(1, 0))\n",
        "        label = center_rot90(label)\n",
        "    # label = np.array(label)\n",
        "\n",
        "    # counter-sensible experiment -- 11:38 20220202\n",
        "    label = center_flip(label)\n",
        "\n",
        "    image = image.astype(np.float32)\n",
        "    return (image, label)\n",
        "\n",
        "# # make_complex_example()\n",
        "# (i, p) = make_complex_dataset()\n",
        "# print('len(i) =', len(i))\n",
        "# print('i[0].dtype =', i[0].dtype)\n",
        "# print('i[0].shape =', i[0].shape)\n",
        "# print('type(i) =', type(i))\n",
        "# print('p[0] =', p[0])\n",
        "\n",
        "def center_rot90(cp): return (cp[1], 0.5 - (cp[0] - 0.5))\n",
        "def center_flip(cp): return (0.5 - (cp[0] - 0.5), cp[1])\n",
        "\n",
        "\n",
        "print('center_flip((0.2, 0.1)) =', center_flip((0.2, 0.1)))\n",
        "print('center_flip([0.2, 0.1]) =', center_flip([0.2, 0.1]))\n",
        "print()\n",
        "print('center_rot90((0.2, 0.1)) =', center_rot90((0.2, 0.1)))\n",
        "print('center_rot90([0.2, 0.1]) =', center_rot90([0.2, 0.1]))\n",
        "print()\n",
        "\n",
        "print('center_rot90((0.8, 0.4)) =', center_rot90((0.8, 0.4)))\n",
        "print('center_rot90((0.4, 0.2)) =', center_rot90((0.4, 0.2)))\n",
        "print('center_rot90((0.2, 0.6)) =', center_rot90((0.2, 0.6)))\n",
        "print('center_rot90((0.6, 0.8)) =', center_rot90((0.6, 0.8)))\n",
        "\n",
        "np.array((1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFDGwHRQ5MGJ",
        "outputId": "d01907b2-f6c9-4d94-e3a5-09ce39d79a28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "center_flip((0.2, 0.1)) = (0.8, 0.1)\n",
            "center_flip([0.2, 0.1]) = (0.8, 0.1)\n",
            "\n",
            "center_rot90((0.2, 0.1)) = (0.1, 0.8)\n",
            "center_rot90([0.2, 0.1]) = (0.1, 0.8)\n",
            "\n",
            "center_rot90((0.8, 0.4)) = (0.4, 0.19999999999999996)\n",
            "center_rot90((0.4, 0.2)) = (0.2, 0.6)\n",
            "center_rot90((0.2, 0.6)) = (0.6, 0.8)\n",
            "center_rot90((0.6, 0.8)) = (0.8, 0.4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New experiment with generators. \n",
        "has exit at end of this "
      ],
      "metadata": {
        "id": "QPEykI8aTmOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ...\n",
        "\n",
        "# a little nugget of code from\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "# which may suggest how I can do \"real-time data augmentation\"\n",
        "#\n",
        "# Maybe I can read the base dataset with 20,000 images, hold them in memory,\n",
        "# then make a Generator (or something that just behaves like it) each batch I\n",
        "# \"flow\" from it will get randomly augumented.\n",
        "#\n",
        "# I assume the call to model.fit(x_batch, y_batch) defaults to a single batch\n",
        "# (epoch=1) do I need to do my own logging etc?\n",
        "#\n",
        "# Note that I am currently using batch_size=128 (of 128x128x3 images).\n",
        "\n",
        "# def dummy():\n",
        "#     # here's a more \"manual\" example\n",
        "#     for e in range(epochs):\n",
        "#         print('Epoch', e)\n",
        "#         batches = 0\n",
        "#         for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
        "#             model.fit(x_batch, y_batch)\n",
        "#             batches += 1\n",
        "#             if batches >= len(x_train) / 32:\n",
        "#                 # we need to break the loop by hand because\n",
        "#                 # the generator loops indefinitely\n",
        "#                 break\n",
        "\n",
        "# Should be able to just call: make_complex_dataset(amplify_2x=False)\n",
        "# to get the non-augmented base dataset of 20,000 images\n",
        "# Then lets split that (80%/20%?) holding out a dataset for evaluation\n",
        "\n",
        "def runtime_augmentation_test(model, epochs, batch_size):\n",
        "    # Read base dataset, return list of images and labels.\n",
        "    base_images, base_labels = make_complex_dataset(amplify_2x=False)\n",
        "    # Split both 80% / 20%.\n",
        "    train_fraction = 0.8\n",
        "    train_count = int(len(base_images) * train_fraction)\n",
        "    train_images = base_images[: train_count]\n",
        "    test_images = base_images[train_count : ]\n",
        "    print('len(train_images) =', len(train_images))\n",
        "    print('len(test_images) =', len(test_images))\n",
        "    print('train_images[0].shape =', train_images[0].shape)\n",
        "    train_labels = base_labels[: train_count]\n",
        "    test_labels = base_labels[train_count : ]\n",
        "    print('len(test_labels) =', len(test_labels))\n",
        "\n",
        "    train_images = np.array(train_images, dtype=np.float32)\n",
        "    train_labels = np.array(train_labels, dtype=np.float32)\n",
        "    test_images = np.array(test_images, dtype=np.float32)\n",
        "    test_labels = np.array(test_labels, dtype=np.float32)\n",
        "\n",
        "    very_temp_train_util(train_images, train_labels, model, epochs, batch_size)\n",
        "\n",
        "def very_temp_train_util(x_train, y_train, model, epochs, batch_size):\n",
        "    # here's a more \"manual\" example\n",
        "    for e in range(epochs):\n",
        "        print('Epoch', e)\n",
        "        # batches = 0\n",
        "        # batch counter\n",
        "        b = 0\n",
        "        # for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
        "        # for x_batch, y_batch in (x_train[b * batch_size: (b + 1) * batch_size],\n",
        "        #                          y_train[b * batch_size: (b + 1) * batch_size]):\n",
        "        while True:\n",
        "            x_batch = x_train[b * batch_size: (b + 1) * batch_size]\n",
        "            y_batch = y_train[b * batch_size: (b + 1) * batch_size]\n",
        "            model.fit(x_batch, y_batch)\n",
        "            # batches += 1\n",
        "            # if batches >= len(x_train) / 32:\n",
        "            b += 1\n",
        "            if b >= len(x_train) / batch_size:\n",
        "                # we need to break the loop by hand because\n",
        "                # the generator loops indefinitely\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "# # debug tests:\n",
        "# epochs = 10\n",
        "# batch_size = 128\n",
        "# model = df.make_disk_finder_model(np.zeros((1, 128, 128, 3)))\n",
        "# runtime_augmentation_test(model, epochs, batch_size)\n",
        "\n",
        "\n",
        "# TODO 20220219 -- build a real generator based on tf.keras.utils.Sequence\n",
        "#\n",
        "# Initially do something like the \"complex dataset\": 20,000 read from disk and\n",
        "#     20,000 more through doing one augmentation per image.\n",
        "#\n",
        "# see example code:\n",
        "#     API doc: tf.keras.utils.Sequence\n",
        "#         https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
        "#     Write your own Custom Data Generator for TensorFlow Keras\n",
        "#         https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
        "\n",
        "# class CIFAR10Sequence(Sequence):\n",
        "# class Find3DisksGenerator(Sequence):\n",
        "class Find3DisksGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    # Construct generator given arrays of base images and labels, and batch size\n",
        "    # def __init__(self, x_set, y_set, batch_size):\n",
        "        # self.x, self.y = x_set, y_set\n",
        "    def __init__(self, base_images, base_labels, batch_size):\n",
        "        self.base_images = base_images\n",
        "        self.base_labels = base_labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    # TODO 20220219 for now assume generator is twice the size of base data.\n",
        "    def __len__(self):\n",
        "        # return math.ceil(len(self.x) / self.batch_size)\n",
        "        return math.ceil(2 * len(self.base_images) / self.batch_size)\n",
        "\n",
        "    # TODO 20220219 for now assume generator is twice the size of base data.\n",
        "    # TODO note this is surely not the most efficient/pythonic way to do this.\n",
        "    # def __getitem__(self, idx):\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # print()\n",
        "        # print('index = ', index)\n",
        "        # print('len(self) = ', len(self))\n",
        "        # print('self.batch_size = ', self.batch_size)\n",
        "        # print('len(self.base_images) = ', len(self.base_images))\n",
        "\n",
        "        # batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        # batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        # Take the next \"half batch\" chunk from base arrays.\n",
        "        # hbs = self.batch_size / 2\n",
        "        # print('hbs = ', hbs)\n",
        "        hbs = int(self.batch_size / 2)\n",
        "        # batch_images = self.base_images[idx * self.batch_size : (idx + 1) * hbs]\n",
        "        # batch_labels = self.base_labels[idx * self.batch_size : (idx + 1) * hbs]\n",
        "        # start = index * self.batch_size\n",
        "        start = index * hbs\n",
        "        end = (index + 1) * hbs\n",
        "        # print('start = ', start)\n",
        "        # print('end = ', end)\n",
        "\n",
        "        batch_images = self.base_images[start : end]\n",
        "        batch_labels = self.base_labels[start : end]\n",
        "\n",
        "        # print('half batch:')\n",
        "        # print('batch_images.shape = ', batch_images.shape)\n",
        "        # print('batch_labels.shape = ', batch_labels.shape)\n",
        "\n",
        "        # Glue two copies of each array together, doubling the size.\n",
        "        batch_images = np.concatenate((batch_images, batch_images), axis=0)\n",
        "        batch_labels = np.concatenate((batch_labels, batch_labels), axis=0)\n",
        "\n",
        "        # print('full batch:')\n",
        "        # print('batch_images.shape = ', batch_images.shape)\n",
        "        # print('batch_labels.shape = ', batch_labels.shape)\n",
        "\n",
        "        # Now for the first \"hbs\" of each, make a modified augmentation.\n",
        "        for i in range(hbs):\n",
        "            image = batch_images[i]\n",
        "            label = batch_labels[i]\n",
        "            image, label = modify_complex_example(image, label)\n",
        "            batch_images[i] = image\n",
        "            batch_labels[i] = label\n",
        "\n",
        "        # print('modified batch:')\n",
        "        # print('batch_images.shape = ', batch_images.shape)\n",
        "        # print('batch_labels.shape = ', batch_labels.shape)\n",
        "\n",
        "        # TODO 20220219 later come back and learn what this means:\n",
        "        # return np.array([\n",
        "        #     resize(imread(file_name), (200, 200))\n",
        "        #        for file_name in batch_x]), np.array(batch_y)\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "\n",
        "# 20220219 note that the pathname from which data is read is not passed in here.\n",
        "#          It is buried down inside make_complex_dataset(). Should it be an arg?\n",
        "\n",
        "def f3d_read_and_split_base_dataset():\n",
        "    # Read base dataset, return list of images and labels.\n",
        "    base_images, base_labels = make_complex_dataset(amplify_2x=False)\n",
        "    # Split both 80% / 20%.\n",
        "    train_fraction = 0.8\n",
        "    train_count = int(len(base_images) * train_fraction)\n",
        "    train_images = base_images[: train_count]\n",
        "    test_images = base_images[train_count : ]\n",
        "    print('len(train_images) =', len(train_images))\n",
        "    print('len(test_images) =', len(test_images))\n",
        "    print('train_images[0].shape =', train_images[0].shape)\n",
        "    train_labels = base_labels[: train_count]\n",
        "    test_labels = base_labels[train_count : ]\n",
        "    print('len(test_labels) =', len(test_labels))\n",
        "\n",
        "    train_images = np.array(train_images, dtype=np.float32)\n",
        "    train_labels = np.array(train_labels, dtype=np.float32)\n",
        "    test_images = np.array(test_images, dtype=np.float32)\n",
        "    test_labels = np.array(test_labels, dtype=np.float32)\n",
        "\n",
        "    # very_temp_train_util(train_images, train_labels, model, epochs, batch_size)\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# 20220219 copied from DiskFind.py\n",
        "# def f3d_train_augmented_model(model, X_train, y_train, X_test, y_test,\n",
        "#                               epochs, batch_size, plot_title):\n",
        "def f3d_train_augmented_model(model, epochs, batch_size, plot_title):\n",
        "    \n",
        "    (train_images, train_labels, test_images, test_labels) = f3d_read_and_split_base_dataset()\n",
        "\n",
        "    training_data_generator = Find3DisksGenerator(train_images, train_labels, batch_size)\n",
        "\n",
        "    # history = model.fit(X_train,\n",
        "    #                     y_train,\n",
        "    #                     validation_data = (X_test, y_test),\n",
        "    history = model.fit(training_data_generator,\n",
        "                        validation_data = (test_images, test_labels),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size)\n",
        "    print()\n",
        "    # plot_accuracy_and_loss(history, plot_title)\n",
        "    df.plot_accuracy_and_loss(history, plot_title)\n",
        "    return history\n",
        "\n",
        "# debug tests:\n",
        "epochs = 100\n",
        "batch_size = 128\n",
        "model = df.make_disk_finder_model(np.zeros((1, 128, 128, 3)))\n",
        "# runtime_augmentation_test(model, epochs, batch_size)\n",
        "f3d_train_augmented_model(model, epochs, batch_size, 'test')\n",
        "\n",
        "# TODO 20220217 stop here rather than proceed on with rest of notebook.\n",
        "assert False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "bdf0a0e03ac04232a0344bcfb51b88a2",
            "b061c7e8f8a446ad87b7645ba0a599ef",
            "f3ba8e9afed344c3b23d1cab26a032a5",
            "05c0f2f14400486a945ca1650ce80615",
            "bf52863177d9404fad2f6e4fc0645a46",
            "56da98ac9bb74d2892a7892bc6e2ff36",
            "58ba5a3b45cc4e6490e6c29b04985e29",
            "edb816385f434ff3b683e1f80a5d1c1f",
            "84a0c1d59c714cc0a316dc4673188483",
            "08e47944c3cf4c1aa2c829dd6cedeaea",
            "939b83438cfb46a3839904e8869507c1"
          ]
        },
        "id": "SC0pFYKVT43b",
        "outputId": "b1a192b6-c151-4e4a-d6da-82364a6cf0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdf0a0e03ac04232a0344bcfb51b88a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/20000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_images) = 16000\n",
            "len(test_images) = 4000\n",
            "train_images[0].shape = (128, 128, 3)\n",
            "len(test_labels) = 4000\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 31s 121ms/step - loss: 0.0525 - accuracy: 0.5027 - in_disk: 0.0616 - val_loss: 0.0452 - val_accuracy: 0.5140 - val_in_disk: 0.0578\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 29s 117ms/step - loss: 0.0430 - accuracy: 0.4959 - in_disk: 0.0629 - val_loss: 0.0484 - val_accuracy: 0.4857 - val_in_disk: 0.0562\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 29s 117ms/step - loss: 0.0424 - accuracy: 0.5004 - in_disk: 0.0625 - val_loss: 0.0439 - val_accuracy: 0.4857 - val_in_disk: 0.0582\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 29s 117ms/step - loss: 0.0420 - accuracy: 0.4977 - in_disk: 0.0613 - val_loss: 0.0415 - val_accuracy: 0.5142 - val_in_disk: 0.0597\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 29s 117ms/step - loss: 0.0415 - accuracy: 0.4994 - in_disk: 0.0631 - val_loss: 0.0414 - val_accuracy: 0.4975 - val_in_disk: 0.0578\n",
            "Epoch 6/100\n",
            " 12/250 [>.............................] - ETA: 27s - loss: 0.0424 - accuracy: 0.4889 - in_disk: 0.0710"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate dataset"
      ],
      "metadata": {
        "id": "HlgYZGvt4zbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_random_seeds()\n",
        "start_time = time.time()\n",
        "\n",
        "# (dataset_images,\n",
        "#  dataset_labels) = make_uniform_dataset(dataset_size = 5000,\n",
        "#                                         image_size = 128,\n",
        "#                                         image_depth = 3) # RGB\n",
        "\n",
        "(dataset_images, dataset_labels) = make_complex_dataset()\n",
        "\n",
        "elapsed_seconds = int(time.time() - start_time)\n",
        "print('Elapsed time: ' + str(elapsed_seconds) + ' seconds (' +\n",
        "      str(int(elapsed_seconds / 60)) +' minutes).')"
      ],
      "metadata": {
        "id": "NgE_VxpN49U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset"
      ],
      "metadata": {
        "id": "P2RaIfYLThfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total dataset size =', len(dataset_images))\n",
        "\n",
        "(images_train, images_test,\n",
        " labels_train, labels_test) = train_test_split(dataset_images,\n",
        "                                               dataset_labels,\n",
        "                                               test_size=0.2)\n",
        " \n",
        "# 20220202 oops, I was keeping these around, think I ought to free them.\n",
        "dataset_images = []\n",
        "dataset_labels = []\n",
        "\n",
        "# Convert from Python lists to np arrays.\n",
        "images_train = np.array(images_train, dtype=np.float32)\n",
        "labels_train = np.array(labels_train, dtype=np.float32)\n",
        "images_test = np.array(images_test, dtype=np.float32)\n",
        "labels_test = np.array(labels_test, dtype=np.float32)\n",
        "\n",
        "\n",
        "print('images_train.shape[0] =', images_train.shape[0])\n",
        "print('labels_train.shape[0] =', labels_train.shape[0])\n",
        "print('images_test.shape[0] =', images_test.shape[0])\n",
        "print('labels_test.shape[0] =', labels_test.shape[0])"
      ],
      "metadata": {
        "id": "3bwzS-uJOuc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize some labels"
      ],
      "metadata": {
        "id": "tXSQ_2SG3he0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_random_seeds()\n",
        "df.visualize_dataset(images = images_test, labels=labels_test)"
      ],
      "metadata": {
        "id": "td99jO4135uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iot7WB8KhGg"
      },
      "source": [
        "# Build and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ppYkZ-grG2E"
      },
      "outputs": [],
      "source": [
        "# Run a model.\n",
        "df.reset_random_seeds()\n",
        "start_time = time.time()\n",
        "fcd_model_timestamp = df.timestamp_string()\n",
        "(model, history) = ([], [])  # To release memory when rerunning in notebook.\n",
        "gc.collect()\n",
        "\n",
        "model = df.make_disk_finder_model(images_train)\n",
        "history = df.run_model(model,\n",
        "                       images_train, labels_train, images_test, labels_test,\n",
        "                       epochs=100,\n",
        "                       batch_size= 128,\n",
        "                       plot_title='F3D')\n",
        "\n",
        "elapsed_seconds = int(time.time() - start_time)\n",
        "print('Elapsed time: ' + str(elapsed_seconds) + ' seconds (' +\n",
        "      str(int(elapsed_seconds / 60)) +' minutes).')\n",
        "\n",
        "# model.save(model_save_directory + fcd_model_timestamp)\n",
        "model_save_path = (model_save_directory +\n",
        "                   fcd_model_timestamp +\n",
        "                   '_Find_3_Disks_complex')\n",
        "model.save(model_save_path)\n",
        "print('Saved trained model to', model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(history))\n",
        "print(type(history.history['loss']))\n",
        "print(len(history.history['loss']))\n",
        "print(history.history['loss'])"
      ],
      "metadata": {
        "id": "7GQ_6teTVVSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize some predictions"
      ],
      "metadata": {
        "id": "e6C1NXAPARMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_random_seeds()\n",
        "# df.visualize_dataset(images=images_test, labels=labels_test, model=model)\n",
        "df.visualize_dataset(images=images_test, labels=labels_test, model=model, count=20)"
      ],
      "metadata": {
        "id": "KJHBxJv_AVXX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}